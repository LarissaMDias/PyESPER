{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "136eaca1",
   "metadata": {},
   "source": [
    "**Python Implementation of Empirical Seawater Property Estimation Routines (ESPERs)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3159882d-34bd-4007-9a88-52a980008431",
   "metadata": {},
   "source": [
    "To run the following examples, please make sure that you have downloaded the required associated files from\n",
    "    the GitHub page as follows:\n",
    "\n",
    "-Mat_fullgrid files: \n",
    "    Folder of .mat files needed for each variable to be estimated, necessary for PyESPER_LIR or PyESPER_Mixed\n",
    "-NeuralNetworks\n",
    "    Folder of .py files needed for each variable to be estimated, necessary for running PyESPER_NN or PyESPER_Mixed\n",
    "    Note: A pickled version of these files is in progress, which should make things easier. \n",
    "-Uncertainty_Polys\n",
    "    Folder of .mat files needed for ach variable to be estimated, necessary for running PyESPER_NN or PyESPER_Mixed\n",
    "-SimpleCantEstimateLR.csv\n",
    "    Necessary for estimating anthropogenic carbon component for pH or DIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33db9f70-d3b7-4679-89ea-b8a32f0526bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PyESPER_LIR(DesiredVariables, Path, OutputCoordinates={}, PredictorMeasurements={}, **kwargs):\n",
    "    \n",
    "    \"\"\"\n",
    "    Locally Interpolated Regressions (LIRs) for Empirical Seawater Property Estimation\n",
    "    Python interpretation of LIRv.3; ESPERv.1.1\n",
    "\n",
    "    Empirical Seawater Property Estimation Routines: Estimates seawater properties and estimate uncertainty from combinations of other parameter\n",
    "    measurements.  PYESPER_LIR refers specifically to code that uses collections of interpolated linear regressions as opposed to neural\n",
    "    networks, and Python rather than MATLAB coding languages.  \n",
    "\n",
    "    Reserved for version update notes: (no updates, first version)\n",
    "  \n",
    "    Documentation and citations:\n",
    "    LIARv1: Carter et al., 2016, doi: 10.1002/lom3.10087\n",
    "    LIARv2, LIPHR, LINR citation: Carter et al., 2018, https://doi.org/10.1002/lom3.10232\n",
    "    LIPR, LISIR, LIOR, first described/used: Carter et al., 2021, https://doi.org/10.1029/2020GB006623\n",
    "    LIRv3 and ESPER_NN (ESPERv1.1): Carter, 2021, https://10.5281/ZENODO.5512697\n",
    "\n",
    "    PyESPER_LIR is a Python replicate of ESPER_LIR:\n",
    "    Carter et al. 2021: https://doi.org/10.1002/lom3.10461\n",
    "    ESPER_NN is inspired by CANYON-B, which also uses neural networks: \n",
    "    Bittig et al. 2018: https://doi.org/10.3389/fmars.2018.00328\n",
    "\n",
    "    This function needs numpy, scipy, pandas, math, matplotlib, importlib, and statistics packages. The seawater package is required if \n",
    "    measurements are provided in molar units or if potential temperature or AOU are needed but not provided by the user.  Scale differences from \n",
    "    TEOS-10 are a negligible component of alkalinity estimate error. PyCO2SYS is required if pH on the total scale is a desired output variable. \n",
    " \n",
    "   ****************************************************************************\n",
    "    Input/Output dimensions:\n",
    "    ............................................................................\n",
    "    p:   Integer number of desired property estimate types (e.g., TA, pH, NO3-)\n",
    "    n:   Integer number of desired estimate locations\n",
    "    e:   Integer number of equations used at each location\n",
    "    y:   Integer number of parameter measurement types provided by the user.\n",
    "    n*e: Total number of estimates returned as an n by e array\n",
    "    ****************************************************************************\n",
    "    \n",
    "    Required Inputs:\n",
    "   \n",
    "    DesiredVariables: (required 1 by p list, where p specifies the desired variable(s) in string format):\n",
    "        List elements specify which variables will be returned. Excepting unitless pH, all outputs are in micromol per kg seawater. Naming of list\n",
    "        elements must be exactly as demonstrated below (exs: [\"TA\"], [\"DIC\", \"phosphate\", \"oxygen\"]).\n",
    "\n",
    "        Desired Variable:                    | List Element Name (String Format):\n",
    "        *********************************************************************\n",
    "        Total Titration Seawater Alkalinity  | TA\n",
    "        Total Dissolved Inorganic Carbon     | DIC\n",
    "        in situ pH on the total scale        | pH\n",
    "        Phosphate                            | phosphate\n",
    "        Nitrate                              | nitrate\n",
    "        Silicate                             | silicate\n",
    "        Dissolved Oxygen (O2)                | oxygen\n",
    "\n",
    "    Path (required string):\n",
    "        Path directing Python to the location of saved/downloaded LIR files on the user's computer (ex: '/Users/lara/Documents/Python'). \n",
    "\n",
    "    OutputCoordinates (required n by 3 dictionary, where n are the number of desired estimate locations and the three dictionary keys are \n",
    "    longitude, latitude, and depth): \n",
    "        Coordinates at which estimates are desired.  The keys should be longitude (degrees E), latitude (degrees N), and positive integer depth  \n",
    "        (m), with dictionary keys named 'longitude', 'latitude', and 'depth' (ex: OutputCoordinates={\"longitude\": [0, 180, -50, 10], \"latitude\": \n",
    "        [85, -20, 18, 0.5], \"depth\": [10, 1000, 0, 0]} or OutputCoordinates={'longitude': long, 'latitude': lat, 'depth': depth} when referring \n",
    "        to a set of predefined lists or numpy arrays of latitude, longitude, and depth information.\n",
    " \n",
    "    PredictorMeasurements (required n by y dictionary, where n are the number of desired estimate locations and y are the dictionary keys  \n",
    "    representing each possible input): \n",
    "       Parameter measurements that will be used to estimate desired variables. Concentrations should be expressed as micromol per kg seawater  \n",
    "       unless PerKgSwTF is set to false in which case they should be expressed as micromol per L, temperature should be expressed as degrees C, and \n",
    "       salinity should be specified with the unitless convention.  NaN inputs are acceptable, but will lead to NaN estimates for any equations that \n",
    "       depend on that parameter.The key order (y columns) is arbitrary, but naming of keys must adhere to  the following convention (ex: \n",
    "       PredictorMeasurements={\"salinity\":[35, 34.1, 32, 33], \"temperature\": [0.1, 10, 0.5, 2], \"oxygen\": [202.3, 214.7, 220.5, 224.2]}or \n",
    "       PredictorMeasurements={'salinity': sal, 'temperature': temp, 'phosphate': phos, 'nitrate': nitr} when referring to predefined lists or \n",
    "       numpy arrays of measurements):\n",
    "\n",
    "       Input Parameter:                       | Dictionary Key Name:\n",
    "       **********************************************************************\n",
    "       Salinity                               | salinity\n",
    "       Temperature                            | temperature\n",
    "       Phosphate                              | phosphate\n",
    "       Nitrate                                | nitrate\n",
    "       Silicate                               | silicate\n",
    "       O2                                     | oxygen   \n",
    "       **********************************************************************\n",
    "       \n",
    "    Optional inputs:  All remaining inputs must be specified as sequential input argument pairs (e.g. \"EstDates\"=EstDates when referring to a \n",
    "    predefined list of dates, 'Equations'=[1:16], pHCalcTF=True, etc.)\n",
    "\n",
    "    EstDates (optional but recommended n by 1 list or 1 by 1 value, default 2002.0): \n",
    "        A list of decimal dates for the estimates (e.g. July 1 2020 would be \"2020.5\").  If only a single date is supplied that value is used\n",
    "        for all estimates.  It is highly recommended that date(s) be provided for estimates of DIC and pH.  This version of the code will accept\n",
    "        1 by n inputs as well.\n",
    "    \n",
    "    Equations (optional 1 by e list, default [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]): \n",
    "        List indicating which equations will be used to estimate desired variables. If [] is input or the input is not specified then all 16 \n",
    "        equations will be used.\n",
    "     \n",
    "         (S=salinity, T=temperature, oxygen=dissolved oxygen molecule... see 'PredictorMeasurements' for units).\n",
    "        ...............................................................\n",
    "        Output Equation Key (See below for explanation of A, B, and C):\n",
    "        1.  S, T, A, B, C\n",
    "        2.  S, T, A, C\n",
    "        3.  S, T, B, C\n",
    "        4.  S, T, C\n",
    "        5.  S, T, A, B\n",
    "        6.  S, T, A\n",
    "        7.  S, T, B\n",
    "        8.  S, T\n",
    "        9.  S, A, B, C\n",
    "        10. S, A, C\n",
    "        11. S, B, C\n",
    "        12. S, C\n",
    "        13. S, A, B\n",
    "        14. S, A\n",
    "        15. S, B\n",
    "        16. S\n",
    "    \n",
    "        DesiredVar   | A             B             C\n",
    "        _____________|_____________________________________\n",
    "        TA           | nitrate       oxygen        silicate\n",
    "        DIC          | nitrate       oxygen        silicate\n",
    "        pH           | nitrate       oxygen        silicate\n",
    "        phosphate    | nitrate       oxygen        silicate\n",
    "        nitrate      | phosphate     oxygen        silicate\n",
    "        silicate     | phosphate     oxygen        nitrate\n",
    "        O2           | phosphate     nitrate       silicate\n",
    "    \n",
    "    MeasUncerts (Optional n by y dictionary or 1 by y dictionary, default: [0.003 S, 0.003 degrees C T or potential temperature, 2% phosphate, \n",
    "    2% nitrate, 2% silicate, 1% AOU or O2]): \n",
    "        Dictionary of measurement uncertainties (see 'PredictorMeasurements' for units). Providing these estimates will improve PyESPER_LIR\n",
    "        estimate uncertainties. Measurement uncertainties are a small part of PyESPER_LIR estimate uncertainties for WOCE-quality measurements. \n",
    "        However, estimate uncertainty scales with measurement uncertainty, so it is recommended that measurement uncertainties be specified for \n",
    "        sensor measurements.  If this optional input argument is not provided, the default WOCE-quality uncertainty is assumed.  If a 1 by y array \n",
    "        is provided then the uncertainty estimates are assumed to apply uniformly to all input parameter measurements. Uncertainties should be \n",
    "        presented with the following naming convention:\n",
    "\n",
    "       Input Uncertainties:                   | Key Name:\n",
    "       ********************************************************\n",
    "       Salinity                               | sal_u\n",
    "       Temperature                            | temp_u\n",
    "       Phosphate                              | phosphate_u\n",
    "       Nitrate                                | nitrate_u\n",
    "       Silicate                               | silicate_u\n",
    "       O2                                     | oxygen_u\n",
    "       \n",
    "    pHCalcTF (Optional boolean, default false): \n",
    "        If set to true, PyESPER will recalculate the pH to be a better estimate of what the seawater pH value would be if calculated from TA and \n",
    "        DIC instead of measured with purified m-cresol dye. This is arguably also a better estimate of the pH that would be obtained from pre-2011\n",
    "        measurements with impure dyes.  See the LIPHR paper for details\n",
    "    \n",
    "    PerKgSwTF (Optional boolean, default true): \n",
    "        Many sensors provide measurements in micromol per L (molarity) instead of micromol per kg seawater. Indicate false if provided\n",
    "        measurements are expressed in molar units (concentrations must be micromol per L if so).  Outputs will remain in molal units regardless.\n",
    "    \n",
    "    VerboseTF (Optional boolean, default true): \n",
    "        Setting this to false will reduce the number of updates, warnings, and errors printed by PyESPER_NN. And additional step can be taken  \n",
    "        before executing the PyESPER_LIR function (see below) that will further reduce updates, warnings, and errors, if desired. \n",
    "        \n",
    "    *************************************************************************\n",
    "    Outputs:\n",
    " \n",
    "    Estimates: \n",
    "        A n by e pandas DataFrame of estimates specific to the coordinates and parameter measurements provided as inputs.  Units are micromoles  \n",
    "        per kg (equivalent to the deprecated microeq per kg seawater). Column names are the unique desired variable-equation combinations  \n",
    "        requested by the user. \n",
    "\n",
    "    Coefficients:\n",
    "        A n by e pandas DataFrame of equation intercepts and coefficients specific to the coordinates and parameter measurements provided as \n",
    "        inputs. Column names are the unique desired variable-equation combinations requested by the user. \n",
    "\t\n",
    "     Uncertainties: \n",
    "        A n by e dictionary of uncertainty estimates specific to the coordinates, parameter measurements, and parameter uncertainties provided.\n",
    "        Units are micromoles per kg (equivalent to the deprecated microeq per kg seawater). Column names are the unique desired variable-equation \n",
    "        combinations requested by the user. \n",
    "        \n",
    "    *************************************************************************\n",
    "    Missing data: should be indicated with a NaN.  A nan coordinate will yield nan estimates for all equations at that coordinate.  A NaN\n",
    "    parameter value will yield NaN estimates for all equations that require that parameter.\n",
    " \n",
    "    *************************************************************************\n",
    "    Please send questions or related requests about PyESPER to lmdias@uw.edu.\n",
    "    ************************************************************************* \n",
    "    \"\"\"\n",
    "\n",
    "     # Importing packages\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import seawater as sw\n",
    "    from scipy.io import loadmat\n",
    "    import time\n",
    "    import scipy.interpolate\n",
    "    from scipy.spatial import Delaunay\n",
    "    import matplotlib.path as mpltPath\n",
    "    import decimal\n",
    "    import PyCO2SYS as pyco2\n",
    "    import math\n",
    "    from scipy.interpolate import griddata\n",
    "\n",
    "     # Starting the timer\n",
    "    tic = time.perf_counter() \n",
    "\n",
    "     # Checking for presence of required input parameters and raising a custom error message if needed\n",
    "    class CustomError(Exception):\n",
    "        pass\n",
    "    \n",
    "    required_coords = (\"longitude\", \"latitude\", \"depth\")\n",
    "    for coord_name in required_coords:\n",
    "        if coord_name not in OutputCoordinates:\n",
    "            raise CustomError(f\"Warning: Missing {coord_name} in OutputCoordinates.\")\n",
    "            \n",
    "    if \"salinity\" not in PredictorMeasurements: \n",
    "        raise CustomError(\"Warning: Missing salinity measurements. Salinity is a required input.\")\n",
    "            \n",
    "    if \"oxygen\" in PredictorMeasurements and \"temperature\" not in PredictorMeasurements:\n",
    "        raise CustomError(\"Warning: Missing temperature measurements. Temperature is required when oxygen is provided.\")\n",
    "\n",
    "    # Check temperature sanity and print a warning for out-of-range values\n",
    "    if \"temperature\" in PredictorMeasurements and any(t < -5 or t > 50 for t in PredictorMeasurements[\"temperature\"]):\n",
    "        print(\"Warning: Temperatures below -5°C or above 50°C found. PyESPER is not designed for seawater with these properties. Ensure temperatures are in Celsius.\")\n",
    "                \n",
    "    if any(s < 5 or s > 50 for s in PredictorMeasurements[\"salinity\"]):\n",
    "        print(\"Warning: Salinities less than 5 or greater than 50 have been found. ESPER is not intended for seawater with these properties.\")\n",
    "        \n",
    "    if any(d < 0 for d in OutputCoordinates[\"depth\"]):\n",
    "        print(\"Warning: Depth can not be negative.\")\n",
    "        \n",
    "    if any(l > 90 for l in OutputCoordinates[\"latitude\"]):\n",
    "        print(\"Warning: A latitude >90 deg (N or S) has been detected. Verify latitude is entered correctly as an input.\")\n",
    "    \n",
    "    # Checking for commonly used missing data indicator flags. Consider adding your commonly used flags here.  \n",
    "    if any(l == -9999 or l == -9 or l == -1e20 for l in OutputCoordinates[\"latitude\"]):\n",
    "           print(\"Warning: A common non-NaN missing data indicator (e.g., -999, -9, -1e20) was detected in the input measurements provided. Missing data should be replaced with NaNs. Otherwise, ESPER will interpret your inputs at face value and give terrible estimates.\")  \n",
    "  \n",
    "    # Check and define Equations based on user-defined kwargs, or use default values\n",
    "    Equations = kwargs.get(\"Equations\", list(range(1, 17)))\n",
    "        \n",
    "    # Reading dimensions of user input\n",
    "    n = max(len(v) for v in OutputCoordinates.values()) # number of rows out\n",
    "    e = len(Equations) # number of Equations\n",
    "    p = len(DesiredVariables) # number of Variables\n",
    "                \n",
    "    # Checking kwargs for presence of VerboseTF and EstDates, and Equations, and defining defaults, as needed\n",
    "    VerboseTF = kwargs.get(\"VerboseTF\", True)\n",
    "        \n",
    "    # Set EstDates based on kwargs, defaulting to 2002.0 if not provided\n",
    "    if \"EstDates\" in kwargs:\n",
    "        d = np.array(kwargs[\"EstDates\"])\n",
    "        EstDates = (\n",
    "            [item for sublist in [kwargs[\"EstDates\"]] * (n + 1) for item in sublist]\n",
    "            if len(d) != n else list(d)\n",
    "        )\n",
    "    else:\n",
    "        EstDates = [2002.0] * n\n",
    "        \n",
    "    # Bookkeeping coordinates\n",
    "    C = {}\n",
    "    longitude = np.array(OutputCoordinates[\"longitude\"])\n",
    "    longitude[longitude > 360] = np.remainder(longitude[longitude > 360], 360)\n",
    "    longitude[longitude < 0] = longitude[longitude<0] + 360\n",
    "    C[\"longitude\"] = longitude\n",
    "    C[\"latitude\"] = OutputCoordinates[\"latitude\"]\n",
    "    C[\"depth\"] = OutputCoordinates[\"depth\"]   \n",
    "    \n",
    "    # Defining or reading in PerKgSwTF\n",
    "    PerKgSwTF = kwargs.get(\"PerKgSwTF\", True)\n",
    "\n",
    "    def process_uncertainties(param, default_factor, PredictorMeasurements, n):\n",
    "        if param in MeasUncerts:\n",
    "            result = np.array(MeasUncerts.get(param))\n",
    "            if len(result) < n:\n",
    "                result = np.tile(result, n)\n",
    "            if param.replace('_u', '') in PredictorMeasurements:\n",
    "                dresult = np.array([i * default_factor for i in PredictorMeasurements[param.replace('_u', '')]])\n",
    "            else:\n",
    "                dresult = result\n",
    "        else:\n",
    "            if param.replace('_u', '') in PredictorMeasurements:\n",
    "                result = np.array([i * default_factor for i in PredictorMeasurements[param.replace('_u', '')]])\n",
    "                dresult = result\n",
    "            else:\n",
    "                result = np.tile('nan', n)\n",
    "                dresult = np.tile(0, n)\n",
    "        return result, dresult\n",
    "\n",
    "    MeasUncerts_processed, DefaultUAll = {}, {}\n",
    "    MeasUncerts = kwargs.get(\"MeasUncerts\", {})\n",
    "\n",
    "    # Validate MeasUncerts dimensions\n",
    "    if MeasUncerts:\n",
    "        if max(len(v) for v in MeasUncerts.values()) != n:\n",
    "            if min(len(v) for v in MeasUncerts.values()) != 1:\n",
    "                raise CustomError(\n",
    "                    \"MeasUncerts must be undefined, a vector with the same number of elements as \"\n",
    "                    \"PredictorMeasurements has columns, or a matrix of identical dimension to PredictorMeasurements.\"\n",
    "                )\n",
    "        if len(MeasUncerts) != len(PredictorMeasurements):\n",
    "            print(\"Warning: Different numbers of input uncertainties and input measurements.\")\n",
    "\n",
    "    # Default salinity uncertainties\n",
    "    sal_u = np.array(MeasUncerts.get(\"sal_u\", [0.003]))\n",
    "    sal_u = np.tile(sal_u, n) if len(sal_u) < n else sal_u\n",
    "    sal_defu = np.tile(0.003, n)\n",
    "\n",
    "    # Temperature uncertainties\n",
    "    temp_u = np.tile(np.array(MeasUncerts.get(\"temp_u\", [0.003])), n) if \"temp_u\" in MeasUncerts or \"temperature\" in PredictorMeasurements else np.tile(\"nan\", n)\n",
    "    temp_defu = np.tile(0.003 if \"temp_u\" in MeasUncerts or \"temperature\" in PredictorMeasurements else 0, n)\n",
    "\n",
    "    # Process other parameters\n",
    "    parameters = {\n",
    "        \"phosphate_u\": 0.02,\n",
    "        \"nitrate_u\": 0.02,\n",
    "        \"silicate_u\": 0.02,\n",
    "        \"oxygen_u\": 0.01\n",
    "    }\n",
    "\n",
    "    for param, factor in parameters.items():\n",
    "        MeasUncerts_processed[param], DefaultUAll[f\"{param.replace('_u', '_defu')}\"] = process_uncertainties(\n",
    "            param, factor, PredictorMeasurements, n\n",
    "        )\n",
    "\n",
    "    # Update MeasUncerts and DefaultUAll dictionaries\n",
    "    meas_uncerts_keys = [\"sal_u\", \"temp_u\", *parameters.keys()]\n",
    "    default_uall_keys = [\"sal_defu\", \"temp_defu\", *[k.replace('_u', '_defu') for k in parameters.keys()]]\n",
    "\n",
    "    MeasUncerts.update(dict(zip(meas_uncerts_keys, [sal_u, temp_u, *MeasUncerts_processed.values()])))\n",
    "    DefaultUAll.update(dict(zip(default_uall_keys, [sal_defu, temp_defu, *DefaultUAll.values()])))\n",
    "\n",
    "    # Create DataFrames\n",
    "    keys = meas_uncerts_keys\n",
    "    Uncerts = np.column_stack([MeasUncerts[k] for k in keys])\n",
    "    Uncertainties_pre = pd.DataFrame(Uncerts, columns=keys)\n",
    "\n",
    "    DUncerts = np.column_stack([DefaultUAll[k] for k in default_uall_keys])\n",
    "    DUncertainties_pre = pd.DataFrame(DUncerts, columns=keys)\n",
    "\n",
    "    # This function is the primary function of the PyESPER_LIR, which preprocesses all data and performs the interpolation\n",
    "    def preprocess_interpolate(\n",
    "        DesiredVariables, \n",
    "        Equations, \n",
    "        EstDates, \n",
    "        VerboseTF, \n",
    "        C={}, \n",
    "        PredictorMeasurements={}, \n",
    "        Uncertainties={}, \n",
    "        DUncertainties={}\n",
    "    ):\n",
    "    \n",
    "        n = max(len(v) for v in C.values()) # number of rows out\n",
    "\n",
    "        # Redefining and organizing all data thus far\n",
    "        order = list(range(n))\n",
    "        input_data = {\n",
    "            \"Order\": order,\n",
    "            \"Longitude\": C[\"longitude\"],\n",
    "            \"Latitude\": C[\"latitude\"],\n",
    "            \"Depth\": C[\"depth\"],\n",
    "            \"Salinity\": PredictorMeasurements[\"salinity\"],\n",
    "            \"Dates\": EstDates,\n",
    "            \"Salinity_u\": Uncertainties[\"sal_u\"],\n",
    "            \"Temperature_u\": Uncertainties[\"temp_u\"],\n",
    "            \"Phosphate_u\": Uncertainties[\"phosphate_u\"],\n",
    "            \"Nitrate_u\": Uncertainties[\"nitrate_u\"],\n",
    "            \"Silicate_u\": Uncertainties[\"silicate_u\"],\n",
    "            \"Oxygen_u\": Uncertainties[\"oxygen_u\"]\n",
    "        }\n",
    "    \n",
    "        # Map PredictorMeasurements keys to input_data keys\n",
    "        for key, label in {\n",
    "            \"temperature\": \"Temperature\",\n",
    "            \"phosphate\": \"Phosphate\",\n",
    "            \"nitrate\": \"Nitrate\",\n",
    "            \"silicate\": \"Silicate\",\n",
    "            \"oxygen\": \"Oxygen\"\n",
    "        }.items():\n",
    "            if key in PredictorMeasurements:\n",
    "                input_data[label] = PredictorMeasurements[key]\n",
    "\n",
    "        InputAll = pd.DataFrame(input_data)\n",
    "        # created a dataframe with order stamp and dropped all nans from a replicate dataframe\n",
    "\n",
    "        # Printing a custom warning if temperature is absent but needed \n",
    "        if \"EstDates\" in kwargs and \"pH\" in DesiredVariables:\n",
    "            if \"temperature\" not in PredictorMeasurements:\n",
    "                print(\n",
    "                    \"Warning: Carbonate system calculations will be used to adjust the pH, but no temperature is \"\n",
    "                    \"specified so 10 C will be assumed. If this is a poor estimate for your region, consider supplying \"\n",
    "                    \"your own value in the PredictorMeasurements input.\"\n",
    "                )\n",
    "                Temperature = [10] * n\n",
    "            else:\n",
    "                Temperature = InputAll[\"Temperature\"]\n",
    "    \n",
    "            PredictorMeasurements[\"temperature\"] = Temperature\n",
    "            InputAll[\"temperature\"] = Temperature\n",
    "\n",
    "        # Beginning treatment of inputs and iterations \n",
    "        depth, latitude, salinity = np.array(C[\"depth\"]), np.array(C[\"latitude\"]), np.array(PredictorMeasurements[\"salinity\"])\n",
    "        temp = np.array(PredictorMeasurements[\"temperature\"]) if \"temperature\" in PredictorMeasurements else np.full(n, 10)\n",
    "        temp_sw = sw.ptmp(salinity, temp, sw.pres(depth, latitude), pr=0)\n",
    "        temperature_processed = [\n",
    "            \"{:.15g}\".format(\n",
    "                {3: 3.000000001, 4: 4.000000001, 5: 5.000000001, 6: 6.000000001}.get(t, 10 if t < -100 else t)\n",
    "            ) \n",
    "            for t in temp_sw\n",
    "        ]\n",
    "        if \"oxygen\" in PredictorMeasurements:\n",
    "            oxyg = np.array(PredictorMeasurements[\"oxygen\"])\n",
    "            oxyg_sw = sw.satO2(salinity, temp_sw)*44.6596 - (oxyg)\n",
    "        else: \n",
    "            oxyg_sw = np.tile(\"nan\", n)\n",
    "        for i in range(len(oxyg_sw)):\n",
    "            if oxyg_sw[i] != \"nan\" and -0.0001 < oxyg_sw[i] < 0.0001:\n",
    "                oxyg_sw[i] = 0\n",
    "        oxygen_processed = [\"{:.5g}\".format(o) if o != \"nan\" else o for o in oxyg_sw]\n",
    "        # Process predictor measurements\n",
    "        processed_measurements = {}\n",
    "        for param in [\"phosphate\", \"nitrate\", \"silicate\"]:\n",
    "            processed_measurements[param] = (\n",
    "        np.array(PredictorMeasurements[param]) if param in PredictorMeasurements else np.tile(\"nan\", n)\n",
    "            )\n",
    "\n",
    "        phosphate_processed = processed_measurements[\"phosphate\"]\n",
    "        nitrate_processed = processed_measurements[\"nitrate\"]\n",
    "        silicate_processed = processed_measurements[\"silicate\"]\n",
    "    \n",
    "        if not PerKgSwTF:\n",
    "            densities = sw.dens(salinity, temperature_processed, sw.pres(depth, latitude)) / 1000\n",
    "            for nutrient in [\"phosphate\", \"nitrate\", \"silicate\"]:\n",
    "                if nutrient in PredictorMeasurements:\n",
    "                    globals()[f\"{nutrient}_processed\"] /= densities\n",
    "            \n",
    "        EqsString = [str(e) for e in Equations]\n",
    "    \n",
    "        NeededForProperty = pd.DataFrame({\n",
    "                 \"TA\": [1, 2, 4, 6, 5], \n",
    "                \"DIC\": [1, 2, 4, 6, 5], \n",
    "                \"pH\": [1, 2, 4, 6, 5],  \n",
    "                \"phosphate\": [1, 2, 4, 6, 5], \n",
    "                \"nitrate\": [1, 2, 3, 6, 5], \n",
    "                \"silicate\": [1, 2, 3, 6, 4], \n",
    "                \"oxygen\": [1, 2, 3, 4, 5]\n",
    "                })\n",
    "            \n",
    "        VarVec = pd.DataFrame({\n",
    "                \"1\": [1, 1, 1, 1, 1],\n",
    "                \"2\": [1, 1, 1, 0, 1],\n",
    "                \"3\": [1, 1, 0, 1, 1],\n",
    "                \"4\": [1, 1, 0, 0, 1],\n",
    "                \"5\": [1, 1, 1, 1, 0],\n",
    "                \"6\": [1, 1, 1, 0, 0],\n",
    "                \"7\": [1, 1, 0, 1, 0],\n",
    "                \"8\": [1, 1, 0, 0, 0],\n",
    "                \"9\": [1, 0, 1, 1, 1],\n",
    "                \"10\": [1, 0, 1, 0, 1],\n",
    "                \"11\": [1, 0, 0, 1, 1],\n",
    "                \"12\": [1, 0, 0, 0, 1],\n",
    "                \"13\": [1, 0, 1, 1, 0],\n",
    "                \"14\": [1, 0, 1, 0, 0],\n",
    "                \"15\": [1, 0, 0, 1, 0],\n",
    "                \"16\": [1, 0, 0, 0, 0],\n",
    "            })\n",
    "    \n",
    "        product, product_processed, name = [], [], []\n",
    "        need, precode, preunc = {}, {}, {}\n",
    "    \n",
    "        # Create a list of names and process products\n",
    "        replacement_map = {\n",
    "            \"0\": \"nan\",\n",
    "            \"1\": \"salinity\",\n",
    "            \"2\": \"temperature\",\n",
    "            \"3\": \"phosphate\",\n",
    "            \"4\": \"nitrate\",\n",
    "            \"5\": \"silicate\",\n",
    "            \"6\": \"oxygen\"\n",
    "        }\n",
    "\n",
    "        for d in DesiredVariables:\n",
    "            dv = NeededForProperty[d]\n",
    "            for e in EqsString:\n",
    "                eq = VarVec[e]\n",
    "                prename = d + e\n",
    "                name.append(prename)\n",
    "                product.append(eq * dv)\n",
    "                prodnp = np.array(eq * dv)\n",
    "\n",
    "                # Replace values using the mapping\n",
    "                processed = np.vectorize(lambda x: replacement_map.get(str(x), x))(prodnp)\n",
    "                need[prename] = processed\n",
    "\n",
    "        for p in range(0, len(product)): # Same but for list of input values\n",
    "            prodnptile = np.tile(product[p], (n, 1))  \n",
    "            prodnptile = prodnptile.astype(\"str\")\n",
    "\n",
    "            for v in range(0, len(salinity)):\n",
    "                prodnptile[v][prodnptile[v] == \"0\"] = \"nan\"\n",
    "                prodnptile[v][prodnptile[v] == \"1\"] = salinity[v]\n",
    "                prodnptile[v][prodnptile[v] == \"2\"] = temperature_processed[v] \n",
    "                prodnptile[v][prodnptile[v] == \"3\"] = phosphate_processed[v]\n",
    "                prodnptile[v][prodnptile[v] == \"4\"] = nitrate_processed[v]\n",
    "                prodnptile[v][prodnptile[v] == \"5\"] = silicate_processed[v]\n",
    "                prodnptile[v][prodnptile[v] == \"6\"] = oxygen_processed[v]\n",
    "                product_processed.append(prodnptile)\n",
    "                \n",
    "        listofprods = list(range(0, len(product)*n, n))\n",
    "        prodlist = []\n",
    "\n",
    "        names_values = list(need.values())\n",
    "        names_keys = list(need.keys())\n",
    "        unc_combo_dict = {}\n",
    "        dunc_combo_dict = {}\n",
    "\n",
    "        def get_uncertainty_array(name, uncertainties, default_size):\n",
    "            if name in uncertainties:\n",
    "                return np.array(uncertainties[name])\n",
    "            else:\n",
    "                return np.full(default_size, np.nan)\n",
    "                \n",
    "        for numb_combos, names_keyscombo in enumerate(names_values):\n",
    "\n",
    "            def define_unc_arrays(lengthofn, listorder, parnames, unames):\n",
    "                for numoptions in range(0, len(parnames)):\n",
    "                    if names_keyscombo[listorder] == parnames[numoptions]:\n",
    "                        udfvalues = np.array(Uncertainties[unames[numoptions]])\n",
    "                        dudfvalues = np.array(DUncertainties[unames[numoptions]])\n",
    "                    elif names_keyscombo[listorder] == \"nan\":\n",
    "                        udfvalues = np.empty((lengthofn))\n",
    "                        udfvalues[:] = np.nan\n",
    "                        dudfvalues = np.empty((lengthofn))\n",
    "                        dudfvalues[:] = np.nan\n",
    "                return udfvalues, dudfvalues\n",
    "            \n",
    "            for names_items in range(0, len(names_keyscombo)): # Fix this later\n",
    "                udfvalues1 = np.array(Uncertainties['sal_u'])\n",
    "                dudfvalues1 = np.array(DUncertainties['sal_u'])\n",
    "                udfvalues2, dudfvalues2 = define_unc_arrays(n, 1, [\"temperature\"], [\"temp_u\"])\n",
    "                udfvalues3, dudfvalues3 = define_unc_arrays(n, 2, [\"nitrate\", \"phosphate\"], [\"nitrate_u\", \"phosphate_u\"])\n",
    "                udfvalues4, dudfvalues4 = define_unc_arrays(n, 3, [\"oxygen\", \"nitrate\"], [\"oxygen_u\", \"nitrate_u\"])\n",
    "                udfvalues5, dudfvalues5 = define_unc_arrays(n, 4, [\"silicate\", \"nitrate\"], [\"silicate_u\", \"nitrate_u\"])\n",
    "               \n",
    "            # Convert to NumPy arrays for efficient comparison\n",
    "            udfvalues = np.array([udfvalues1, udfvalues2, udfvalues3, udfvalues4, udfvalues5])\n",
    "            dudfvalues = np.array([dudfvalues1, dudfvalues2, dudfvalues3, dudfvalues4, dudfvalues5])\n",
    "\n",
    "            # Update `udfvalues` based on `dudfvalues` using element-wise maximum\n",
    "            udfvalues = np.maximum(udfvalues, dudfvalues)\n",
    "\n",
    "            # Create DataFrames and set column names\n",
    "            new_unames = ['US', 'UT', 'UA', 'UB', 'UC']\n",
    "            uncertaintyvalues_df = pd.DataFrame(udfvalues.T, columns=new_unames)\n",
    "            duncertaintyvalues_df = pd.DataFrame(dudfvalues.T, columns=new_unames)\n",
    "\n",
    "            # Update dictionaries\n",
    "            unc_combo_dict[names_keys[numb_combos]] = uncertaintyvalues_df\n",
    "            dunc_combo_dict[names_keys[numb_combos]] = duncertaintyvalues_df\n",
    "\n",
    "        # Append the required products to `prodlist` and populate `precode`\n",
    "        prodlist = [product_processed[item] for item in listofprods]\n",
    "        precode = {name[i]: prodlist[i] for i in range(len(listofprods))}\n",
    "\n",
    "        S, T, A, B, Z, code = [], [], [], [], [], {}\n",
    "    \n",
    "        for value in precode.values():\n",
    "            S.append(value[:, 0])\n",
    "            T.append(value[:, 1])\n",
    "            A.append(value[:, 2])\n",
    "            B.append(value[:, 3])\n",
    "            Z.append(value[:, 4])\n",
    "        \n",
    "        codenames = list(precode.keys())\n",
    "        \n",
    "        for n, code_name in enumerate(codenames):\n",
    "            # Create a DataFrame for each set of data\n",
    "            data = [S[n], T[n], A[n], B[n], Z[n]]\n",
    "            p = pd.DataFrame(data).T\n",
    "            p.columns = [\"S\", \"T\", \"A\", \"B\", \"C\"]\n",
    "            \n",
    "            # Assign the DataFrame to the dictionary with the code name as the key\n",
    "            code[code_name] = p\n",
    "\n",
    "            # List of common columns to be added\n",
    "            common_columns = [\"Order\", \"Dates\", \"Longitude\", \"Latitude\", \"Depth\", \"Salinity_u\", \"Temperature_u\", \n",
    "                              \"Phosphate_u\", \"Nitrate_u\", \"Silicate_u\", \"Oxygen_u\"]\n",
    "\n",
    "            # Assign the common columns from InputAll to the DataFrame\n",
    "            code[code_name][common_columns] = InputAll[common_columns]\n",
    "        \n",
    "        # Loading the data\n",
    "        AAIndsCs, GridCoords, Cs = {}, {}, {}\n",
    "        def fetch_data (DesiredVariables):\n",
    "            for v in DesiredVariables:               \n",
    "                P = Path\n",
    "                fname1 = f\"{P}/PyESPER/full_Grid_LIRs/LIR_files_{v}_fullCs1.mat\"\n",
    "                fname2 = f\"{P}/PyESPER/full_Grid_LIRs/LIR_files_{v}_fullCs2.mat\"\n",
    "                fname3 = f\"{P}/PyESPER/full_Grid_LIRs/LIR_files_{v}_fullCs3.mat\"\n",
    "                fname4 = f\"{P}/PyESPER/full_Grid_LIRs/LIR_files_{v}_fullGrids.mat\"\n",
    "\n",
    "                Cs1 = loadmat(fname1)\n",
    "                Cs2 = loadmat(fname2)\n",
    "                Cs3 = loadmat(fname3)\n",
    "                Grid = loadmat(fname4)\n",
    "                \n",
    "                UncGrid = Grid[\"UncGrid\"][0][0] \n",
    "                GridCoodata, AAinds = np.array(Grid[\"GridCoords\"]), np.array(Grid[\"AAIndsM\"])\n",
    "                Csdata1, Csdata2, Csdata3 = np.array(Cs1[\"Cs1\"]), np.array(Cs2[\"Cs2\"]), np.array(Cs3[\"Cs3\"]) \n",
    "                AAIndsCs[v] = pd.DataFrame(data=AAinds)\n",
    "                GridCoords[v] = pd.DataFrame(data=GridCoodata[:, :])\n",
    "                Csdata = np.concatenate((Csdata1, Csdata2, Csdata3), axis=1)\n",
    "                Cs[v] = [pd.DataFrame(data=Csdata[:, :, i]) for i in range(16)]\n",
    "      \n",
    "            LIR_data = [GridCoords, Cs, AAIndsCs, UncGrid]\n",
    "            return LIR_data\n",
    "\n",
    "        LIR_data = fetch_data(DesiredVariables)\n",
    "        \n",
    "        # Assessing the locations/regions of user-provided outputcoordinates\n",
    "        # Define Polygons\n",
    "        LNAPoly = np.array([[300, 0], [260, 20], [240, 67], [260, 40], [361, 40], [361, 0], [298, 0]])\n",
    "        LSAPoly = np.array([[298, 0], [292, -40.01], [361, -40.01], [361, 0], [298, 0]])\n",
    "        LNAPolyExtra = np.array([[-1, 50], [40, 50], [40, 0], [-1, 0], [-1, 50]])\n",
    "        LSAPolyExtra = np.array([[-1, 0], [20, 0], [20, -40], [-1, -40], [-1, 0]])\n",
    "        LNOPoly = np.array([[361, 40], [361, 91], [-1, 91], [-1, 50], [40, 50], [40, 40], [104, 40], [104, 67], [240, 67],\n",
    "                            [280, 40], [361, 40]])\n",
    "        xtra = np.array([[0.5, -39.9], [.99, -39.9], [0.99, -40.001], [0.5, -40.001]])\n",
    "\n",
    "        polygons = [LNAPoly, LSAPoly, LNAPolyExtra, LSAPolyExtra, LNOPoly, xtra]\n",
    "\n",
    "        # Create Paths\n",
    "        paths = [mpltPath.Path(poly) for poly in polygons]\n",
    "\n",
    "        # Extract coordinates\n",
    "        longitude, latitude, depth = np.array(C[\"longitude\"]), np.array(C[\"latitude\"]), np.array(C[\"depth\"])\n",
    "    \n",
    "        # Check if coordinates are within each polygon\n",
    "        conditions = [path.contains_points(np.column_stack((longitude, latitude))) for path in paths]\n",
    "\n",
    "        # Combine conditions\n",
    "        AAIndsM = np.logical_or.reduce(conditions)\n",
    "\n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame({'AAInds': AAIndsM, 'Lat': latitude, 'Lon': longitude, 'Depth': depth})\n",
    "\n",
    "        for df_code in code.values():\n",
    "            df_code['AAInds'] = df['AAInds']\n",
    "        \n",
    "        # Initialize dictionaries for AA and Else data\n",
    "        AAdata = {}\n",
    "        Elsedata = {}\n",
    "\n",
    "        # Iterate over each key in code\n",
    "        for i in code:\n",
    "            # Extract data arrays from the DataFrame\n",
    "            data_arrays = np.array([code[i][key].values for key in ['Depth', 'Latitude', 'Longitude', 'S', 'T', 'A', 'B', 'C', \n",
    "                                                                    'Order', 'Salinity_u', 'Temperature_u', 'Phosphate_u', \n",
    "                                                                    'Nitrate_u', 'Silicate_u', 'Oxygen_u', 'AAInds']])\n",
    "\n",
    "            # Unpack arrays into separate variables\n",
    "            depth, latitude, longitude, S, T, A, B, C, order, sal_u, temp_u, phos_u, nitr_u, sil_u, oxyg_u, aainds = data_arrays\n",
    "    \n",
    "            # Normalize the depth values\n",
    "            depth = depth / 25\n",
    "            # Reshape data arrays to match the number of rows\n",
    "            NumRows_out = len(longitude)\n",
    "            reshaped_data = [arr.reshape(NumRows_out, 1) for arr in [depth, latitude, longitude, S, T, A, B, C, order, sal_u, \n",
    "                                                                     temp_u, phos_u, nitr_u, sil_u, oxyg_u, aainds]]\n",
    "            dep, lat, lon, sal, temp, avar, bvar, cvar, orde, salu, tempu, phosu, nitru, silu, oxygu, aai = reshaped_data\n",
    "    \n",
    "            # Combine the data into one array for further splitting\n",
    "            InputBool = np.hstack(reshaped_data)\n",
    "    \n",
    "            # Define columns for the final DataFrame\n",
    "            columns = ['d2d', 'Latitude', 'Longitude', 'S', 'T', 'A', 'B', 'C', 'Order', 'Salinity_u', 'Temperature_u', \n",
    "                       'Phosphate_u', 'Nitrate_u', 'Silicate_u', 'Oxygen_u', 'AAInds']\n",
    "            NumCols_out = len(columns)\n",
    "\n",
    "            # Function to filter arrays based on condition\n",
    "            def split(arr, cond):\n",
    "                return arr[cond]\n",
    "\n",
    "            # Split the data into AA and Else data\n",
    "            InputAA_01 = split(InputBool, InputBool[:, -1] == 1)\n",
    "            InputElse_01 = split(InputBool, InputBool[:, -1] == 0)\n",
    "\n",
    "            # Reshape and create DataFrames for AA and Else\n",
    "            AAInput = pd.DataFrame(InputAA_01.reshape(len(InputAA_01), NumCols_out), columns=columns)\n",
    "            ElseInput = pd.DataFrame(InputElse_01.reshape(len(InputElse_01), NumCols_out), columns=columns)\n",
    "\n",
    "            # Store the results in the dictionaries\n",
    "            AAdata[i] = AAInput\n",
    "            Elsedata[i] = ElseInput\n",
    "\n",
    "        # Use boolean for AA or Else to separate coefficients into Atlantic or not\n",
    "        GridCoords, Cs, AAInds = LIR_data[:3]    \n",
    "        DVs, CsVs = list(Cs.keys()), list(Cs.values())   \n",
    "        ListVars, NumVars = list(range(len(AAInds))), len(AAInds)\n",
    "        GridValues, AAIndValues = list(GridCoords.values())[0], list(AAInds.values())[0]\n",
    "    \n",
    "        lon_grid, lat_grid, d2d_grid, aainds = np.array((GridValues[0])), np.array((GridValues[1])), \\\n",
    "           np.array(GridValues[2])/25, np.array(AAIndValues[0])\n",
    "        names = ['lon', 'lat', 'd2d', \"C_alpha\", \"C_S\", \"C_T\", \"C_A\", \"C_B\", \"C_C\", 'AAInds']\n",
    "    \n",
    "        Gdf, CsDesired = {}, {}   \n",
    "        for l, name in zip(ListVars, DVs):\n",
    "            Cs2 = CsVs[:][l][:]\n",
    "            for e in Equations:\n",
    "                CsName = f'Cs{name}{e}'\n",
    "                CsDesired[CsName] = Cs2[e-1][:]\n",
    "                Cs3 = Cs2[e-1][:]\n",
    "                C_alpha, C_S, C_T, C_A, C_B, C_C = np.array(Cs3[0]), np.array(Cs3[1]), np.array(Cs3[2]), np.array(Cs3[3]), \\\n",
    "                    np.array(Cs3[4]), np.array(Cs3[5])\n",
    "                grid_indices = np.column_stack((lon_grid, lat_grid, d2d_grid, C_alpha, C_S, C_T, C_A, C_B, C_C, aainds))\n",
    "                Gdf[f\"{name}{e}\"] = pd.DataFrame(data=grid_indices, columns=names)\n",
    "                \n",
    "        # Interpolate\n",
    "        Gkeys, Gvalues = list(Gdf.keys()), list(Gdf.values())\n",
    "        AAOkeys, AAOvalues, ElseOkeys, ElseOvalues = list(AAdata.keys()), list(AAdata.values()), list(Elsedata.keys()), \\\n",
    "            list(Elsedata.values())\n",
    "\n",
    "        def process_grid(grid_values, data_values):\n",
    "            results = []\n",
    "            for i in range(len(grid_values)):\n",
    "                grid = grid_values[i]\n",
    "                points = np.array([list(grid['lon']), list(grid['lat']), list(grid['d2d'])]).T\n",
    "                tri = Delaunay(points)\n",
    "        \n",
    "                values = np.array([\n",
    "                    list(grid['C_alpha']),\n",
    "                    list(grid['C_S']),\n",
    "                    list(grid['C_T']),\n",
    "                    list(grid['C_A']),\n",
    "                    list(grid['C_B']),\n",
    "                    list(grid['C_C'])\n",
    "                ]).T\n",
    "                interpolant = scipy.interpolate.LinearNDInterpolator(tri, values) \n",
    "                        \n",
    "                data = data_values[i]\n",
    "                points_to_interpolate = (list(data['Longitude']), list(data['Latitude']), list(data['d2d']))\n",
    "                results.append(interpolant(points_to_interpolate))\n",
    "\n",
    "            return results, interpolant\n",
    "\n",
    "        # Process AA and EL grids\n",
    "        aaLCs, aaInterpolants_pre = process_grid(Gvalues, AAOvalues)\n",
    "        elLCs, elInterpolants_pre = process_grid(Gvalues, ElseOvalues)   \n",
    "\n",
    "        # Initialize lists for storing interpolated values\n",
    "        aaIntCT2, aaIntCA2, aaIntCB2, aaIntCC2, aaTo2, aaAo2, aaBo2, aaCo2 = [[] for _ in range(8)]\n",
    "        elIntCT2, elIntCA2, elIntCB2, elIntCC2, elTo2, elAo2, elBo2, elCo2 = [[] for _ in range(8)]\n",
    "        aaInterpolants, elInterpolants = {}, {}  \n",
    "\n",
    "        for i in range(0, len(aaLCs)): \n",
    "            aaIntalpha, elIntalpha = aaLCs[i][:, 0], elLCs[i][:, 0]\n",
    "            aaIntCS, elIntCS = aaLCs[i][:, 1], elLCs[i][:, 1]\n",
    "            aaIntCT, elIntCT = aaLCs[i][:, 2], elLCs[i][:, 2]\n",
    "            aaIntCA, elIntCA = aaLCs[i][:, 3], elLCs[i][:, 3]\n",
    "            aaIntCB, elIntCB = aaLCs[i][:, 4], elLCs[i][:, 4]\n",
    "            aaIntCC, elIntCC = aaLCs[i][:, 5], elLCs[i][:, 5]\n",
    "\n",
    "            # Handle missing data (NaN handling)\n",
    "            def process_list(int_values, val_values):\n",
    "                int2, val2 = [], []\n",
    "                for item, val in zip(int_values, val_values):\n",
    "                    int2.append(0 if pd.isna(item) else item)\n",
    "                    val2.append(0 if val == \"nan\" else val)\n",
    "                return int2, val2\n",
    "            # Reprocessing \"NaN\" to 0 as needed for calculations\n",
    "\n",
    "            key = Gkeys[i]\n",
    "            is_key_1 = key[-1] == \"1\" and key[-2] != \"1\"\n",
    "            is_key_2 = key[-1] == \"2\" and key[-2] != \"1\"\n",
    "            is_key_3 = key[-1] == \"3\" and key[-2] != \"1\"\n",
    "            is_key_4 = key[-1] == \"4\" and key[-2] != \"1\"\n",
    "            is_key_5 = key[-1] == \"5\" and key[-2] != \"1\"\n",
    "            is_key_6 = key[-1] == \"6\" and key[-2] != \"1\"\n",
    "            is_key_7 = key[-1] == \"7\" \n",
    "            is_key_8 = key[-1] == \"8\" \n",
    "            is_key_9 = key[-1] == \"9\" \n",
    "            is_key_10 = key[-1] == \"0\" and Gkeys[i][-2] == \"1\"\n",
    "            is_key_11 = key[-1] == \"1\" and key[-2] == \"1\"\n",
    "            is_key_12 = key[-1] == \"2\" and key[-2] == \"1\"\n",
    "            is_key_13 = key[-1] == \"3\" and key[-2] == \"1\"\n",
    "            is_key_14 = key[-1] == \"4\" and key[-2] == \"1\"\n",
    "            is_key_15 = key[-1] == \"5\" and key[-2] == \"1\"\n",
    "            is_key_16 = key[-1] == \"6\" and key[-2] == \"1\"\n",
    "\n",
    "            aaDatao = AAOvalues[i]\n",
    "            aaSo, aaTo, aaAo, aaBo, aaCo = aaDatao['S'], aaDatao['T'], aaDatao['A'], aaDatao['B'], aaDatao['C']\n",
    "\n",
    "            # Determine which values to use \n",
    "            if is_key_1:\n",
    "                aaIntCT2, aaIntCA2, aaIntCB2, aaIntCC2 = aaIntCT, aaIntCA, aaIntCB, aaIntCC \n",
    "                aaTo2, aaAo2, aaBo2, aaCo2 = aaTo, aaAo, aaBo, aaCo\n",
    "\n",
    "            elif is_key_2:\n",
    "                aaIntCT2, aaIntCA2, aaIntCC2 = aaIntCT, aaIntCA, aaIntCC\n",
    "                aaTo2, aaAo2, aaCo2 = aaTo, aaAo, aaCo\n",
    "\n",
    "                aaIntCB2, aaBo2 = process_list(aaIntCB, aaBo)\n",
    "\n",
    "            elif is_key_3:\n",
    "                aaIntCT2, aaIntCB2, aaIntCC2 = aaIntCT, aaIntCB, aaIntCC\n",
    "                aaTo2, aaBo2, aaCo2 = aaTo, aaBo, aaCo\n",
    "\n",
    "                aaIntCA2, aaAo2 = process_list(aaIntCA, aaAo)\n",
    "\n",
    "            elif is_key_4:\n",
    "                aaIntCT2, aaIntCC2 = aaIntCT, aaIntCC\n",
    "                aaTo2, aaCo2 = aaTo, aaCo\n",
    "                aaIntCA2, aaAo2 = process_list(aaIntCA, aaAo)\n",
    "                aaIntCB2, aaBo2 = process_list(aaIntCB, aaBo)\n",
    "\n",
    "            elif is_key_5:\n",
    "                aaIntCT2, aaIntCA2, aaIntCB2 = aaIntCT, aaIntCA, aaIntCB\n",
    "                aaTo2, aaAo2, aaBo2 = aaTo, aaAo, aaBo\n",
    "                aaIntCC2, aaCo2 = process_list(aaIntCC, aaCo)\n",
    "    \n",
    "            elif is_key_6:\n",
    "                aaIntCT2, aaIntCA2 = aaIntCT, aaIntCA\n",
    "                aaTo2, aaAo2 = aaTo, aaAo\n",
    "                aaIntCB2, aaBo2 = process_list(aaIntCB, aaBo)\n",
    "                aaIntCC2, aaCo2 = process_list(aaIntCC, aaCo)\n",
    " \n",
    "            elif is_key_7:\n",
    "                aaIntCT2, aaIntCB2 = aaIntCT, aaIntCB\n",
    "                aaTo2, aaBo2 = aaTo, aaBo\n",
    "\n",
    "                aaIntCA2, aaAo2 = process_list(aaIntCA, aaAo)\n",
    "                aaIntCC2, aaCo2 = process_list(aaIntCC, aaCo)\n",
    "\n",
    "            elif is_key_8:\n",
    "                aaIntCT2 = aaIntCT\n",
    "                aaTo2 = aaTo\n",
    "\n",
    "                aaIntCA2, aaAo2 = process_list(aaIntCA, aaAo)\n",
    "                aaIntCB2, aaBo2 = process_list(aaIntCB, aaBo)\n",
    "                aaIntCC2, aaCo2 = process_list(aaIntCC, aaCo)\n",
    "                \n",
    "            elif is_key_9:\n",
    "                aaIntCA2, aaIntCB2, aaIntCC2 = aaIntCA, aaIntCB, aaIntCC\n",
    "                aaAo2, aaBo2, aaCo2 = aaAo, aaBo, aaCo\n",
    "\n",
    "                aaIntCT2, aaTo2 = process_list(aaIntCT, aaTo)\n",
    " \n",
    "            elif is_key_10:\n",
    "                aaIntCA2, aaIntCC2 = aaIntCA, aaIntCC\n",
    "                aaAo2, aaCo2 = aaAo, aaCo\n",
    "                aaIntCT2, aaTo2 = process_list(aaIntCT, aaTo)\n",
    "                aaIntCB2, aaBo2 = process_list(aaIntCB, aaBo)\n",
    "\n",
    "            elif is_key_11:\n",
    "                aaIntCB2, aaIntCC2 = aaIntCB, aaIntCC\n",
    "                aaBo2, aaCo2 = aaBo, aaCo\n",
    "                aaIntCT2, aaTo2 = process_list(aaIntCT, aaTo)\n",
    "                aaIntCA2, aaAo2 = process_list(aaIntCA, aaAo)\n",
    "                \n",
    "            elif is_key_12:\n",
    "                aaIntCC2 = aaIntCC\n",
    "                aaCo2 = aaCo\n",
    "\n",
    "                aaIntCT2, aaTo2 = process_list(aaIntCT, aaTo)\n",
    "                aaIntCA2, aaAo2 = process_list(aaIntCA, aaAo)\n",
    "                aaIntCB2, aaBo2 = process_list(aaIntCB, aaBo)\n",
    "\n",
    "            elif is_key_13:\n",
    "                aaIntCA2, aaIntCB2 = aaIntCA, aaIntCB\n",
    "                aaAo2, aaBo2 = aaAo, aaBo\n",
    "\n",
    "                aaIntCT2, aaTo2 = process_list(aaIntCT, aaTo)\n",
    "                aaIntCC2, aaCo2 = process_list(aaIntCC, aaCo)\n",
    "                \n",
    "            elif is_key_14:\n",
    "                aaIntCA2 = aaIntCA\n",
    "                aaAo2 = aaAo\n",
    "                aaIntCT2, aaTo2 = process_list(aaIntCT, aaTo)\n",
    "                aaIntCB2, aaBo2 = process_list(aaIntCB, aaBo)\n",
    "                aaIntCC2, aaCo2 = process_list(aaIntCC, aaCo)\n",
    "\n",
    "            elif is_key_15:\n",
    "                aaIntCB2 = aaIntCB\n",
    "                aaBo2 = aaBo\n",
    "    \n",
    "                aaIntCT2, aaTo2 = process_list(aaIntCT, aaTo)\n",
    "                aaIntCA2, aaAo2 = process_list(aaIntCA, aaAo)\n",
    "                aaIntCC2, aaCo2 = process_list(aaIntCC, aaCo)\n",
    "\n",
    "            elif is_key_16:\n",
    "                aaIntCT2, aaTo2 = process_list(aaIntCT, aaTo)\n",
    "                aaIntCA2, aaAo2 = process_list(aaIntCA, aaAo)\n",
    "                aaIntCB2, aaBo2 = process_list(aaIntCB, aaBo)\n",
    "                aaIntCC2, aaCo2 = process_list(aaIntCC, aaCo)\n",
    "\n",
    "            # Convert data lists to NumPy arrays and fix specific value\n",
    "            aaAo2 = ['-0.000002' if x == '-2.4319000000000003e-' else x for x in aaAo2]\n",
    "            data = [aaIntalpha, aaIntCS, aaIntCT2, aaIntCA2, aaIntCB2, aaIntCC2, aaSo, aaTo2, aaAo2, aaBo2, aaCo2]\n",
    "            aaIal, aaICS, aaICT, aaICA, aaICB, aaICC, aaS, aaT, aaA, aaB, aaC = map(lambda x: np.array(x, dtype=float), data)\n",
    "\n",
    "            # Compute `aaEst`\n",
    "            aaEst = np.array([a + b*c + d*e + f*g + h*i + j*k \n",
    "                              for a, b, c, d, e, f, g, h, i, j, k \n",
    "                              in zip(aaIal, aaICS, aaS, aaICT, aaT, aaICA, aaA, aaICB, aaB, aaICC, aaC)])\n",
    "        \n",
    "            # Store results\n",
    "            aaInterpolants[key] = (aaIal, aaICS, aaICT, aaICA, aaICB, aaICC, aaEst)\n",
    "\n",
    "            # Reprocessing \"NaN\" to 0 as needed for calculations\n",
    "            elDatao = ElseOvalues[i]\n",
    "            elSo, elTo, elAo, elBo, elCo = elDatao['S'], elDatao['T'], elDatao['A'], elDatao['B'], elDatao['C']\n",
    "\n",
    "            # Determine which values to use\n",
    "            if is_key_1:\n",
    "                elIntCT2, elIntCA2, elIntCB2, elIntCC2 = elIntCT, elIntCA, elIntCB, elIntCC\n",
    "                elTo2, elAo2, elBo2, elCo2 = elTo, elAo, elBo, elCo\n",
    "\n",
    "            elif is_key_2:\n",
    "                elIntCT2, elIntCA2, elIntCC2 = elIntCT, elIntCA, elIntCC\n",
    "                elTo2, elAo2, elCo2 = elTo, elAo, elCo\n",
    "\n",
    "                elIntCB2, elBo2 = process_list(elIntCB, elBo)\n",
    "\n",
    "            elif is_key_3:\n",
    "                elIntCT2, elIntCB2, elIntCC2 = elIntCT, elIntCB, elIntCC\n",
    "                elTo2, elBo2, elCo2 = elTo, elBo, elCo\n",
    "\n",
    "                elIntCA2, elAo2 = process_list(elIntCA, elAo)\n",
    "\n",
    "            elif is_key_4:\n",
    "                elIntCT2, elIntCC2 = elIntCT, elIntCC\n",
    "                elTo2, elCo2 = elTo, elCo\n",
    "\n",
    "                elIntCA2, elAo2 = process_list(elIntCA, elAo)\n",
    "                elIntCB2, elBo2 = process_list(elIntCB, elBo)\n",
    "\n",
    "            elif is_key_5:\n",
    "                elIntCT2, elIntCA2, elIntCB2 = elIntCT, elIntCA, elIntCB\n",
    "                elTo2, elAo2, elBo2 = elTo, elAo, elBo\n",
    "\n",
    "                elIntCC2, elCo2 = process_list(elIntCC, elCo)\n",
    "\n",
    "            elif is_key_6:\n",
    "                elIntCT2, elIntCA2 = elIntCT, elIntCA\n",
    "                elTo2, elAo2 = elTo, elAo\n",
    "\n",
    "                elIntCB2, elBo2 = process_list(elIntCB, elBo)\n",
    "                elIntCC2, elCo2 = process_list(elIntCC, elCo)\n",
    " \n",
    "            elif is_key_7:\n",
    "                elIntCT2, elIntCB2 = elIntCT, elIntCB\n",
    "                elTo2, elBo2 = elTo, elBo\n",
    "\n",
    "                elIntCA2, elAo2 = process_list(elIntCA, elAo)\n",
    "                elIntCC2, elCo2 = process_list(elIntCC, elCo)\n",
    "\n",
    "            elif is_key_8:\n",
    "                elIntCT2 = elIntCT\n",
    "                elTo2 = elTo\n",
    "\n",
    "                elIntCA2, elAo2 = process_list(elIntCA, elAo)\n",
    "                elIntCB2, elBo2 = process_list(elIntCB, elBo)\n",
    "                elIntCC2, elCo2 = process_list(elIntCC, elCo)\n",
    "                \n",
    "            elif is_key_9:\n",
    "                elIntCA2, elIntCB2, elIntCC2 = elIntCA, elIntCB, elIntCC\n",
    "                elAo2, elBo2, elCo2 = elAo, elBo, elCo\n",
    "\n",
    "                elIntCT2, elTo2 = process_list(elIntCT, elTo)\n",
    "\n",
    "            elif is_key_10:\n",
    "                elIntCA2, elIntCC2 = elIntCA, elIntCC\n",
    "                elAo2, elCo2 = elAo, elCo\n",
    "\n",
    "                elIntCT2, elTo2 = process_list(elIntCT, elTo)\n",
    "                elIntCB2, elBo2 = process_list(elIntCB, elBo)\n",
    "\n",
    "            elif is_key_11:\n",
    "                elIntCB2, elIntCC2 = elIntCB, elIntCC\n",
    "                elBo2, elCo2 = elBo, elCo\n",
    "\n",
    "                elIntCT2, elTo2 = process_list(elIntCT, elTo)\n",
    "                elIntCA2, elAo2 = process_list(elIntCA, elAo)\n",
    "                \n",
    "            elif is_key_12:\n",
    "                elIntCC2 = elIntCC\n",
    "                elCo2 = elCo\n",
    "\n",
    "                elIntCT2, elTo2 = process_list(elIntCT, elTo)\n",
    "                elIntCA2, elAo2 = process_list(elIntCA, elAo)\n",
    "                elIntCB2, elBo2 = process_list(elIntCB, elBo)\n",
    "\n",
    "            elif is_key_13:\n",
    "                elIntCA2, elIntCB2 = elIntCA, elIntCB\n",
    "                elAo2, elBo2 = elAo, elBo\n",
    "\n",
    "                elIntCT2, elTo2 = process_list(elIntCT, elTo)\n",
    "                elIntCC2, elCo2 = process_list(elIntC, elCo)\n",
    "                \n",
    "            elif is_key_14:\n",
    "                elIntCA2 = elIntCA\n",
    "                elAo2 = elAo\n",
    "\n",
    "                elIntCT2, elTo2 = process_list(elIntCT, elTo)\n",
    "                elIntCB2, elBo2 = process_list(elIntCB, elBo)\n",
    "                elIntCC2, elCo2 = process_list(elIntCC, elCo)\n",
    "\n",
    "            elif is_key_15:\n",
    "                elIntCB2 = elIntCB\n",
    "                elBo2 = elBo\n",
    "\n",
    "                elIntCT2, elTo2 = process_list(elIntCT, elTo)\n",
    "                elIntCA2, elAo2 = process_list(elIntCA, elAo)\n",
    "                elIntCC2, elCo2 = process_list(elIntCC, elCo)\n",
    "\n",
    "            elif is_key_16:\n",
    "\n",
    "                elIntCT2, elTo2 = process_list(elIntCT, elTo)\n",
    "                elIntCA2, elAo2 = process_list(elIntCA, elAo)\n",
    "                elIntCB2, elBo2 = process_list(elIntCB, elBo)\n",
    "                elIntCC2, elCo2 = process_list(elIntCC, elCo)\n",
    "\n",
    "\n",
    "            # Convert all input lists to NumPy arrays in one go\n",
    "            data2 = [elIntalpha, elIntCS, elIntCT2, elIntCA2, elIntCB2, elIntCC2, elSo, elTo2, elAo2, elBo2, elCo2]\n",
    "            elIal, elICS, elICT, elICA, elICB, elICC, elS, elT, elA, elB, elC = map(lambda x: np.array(x, dtype=float), data2)\n",
    "\n",
    "            # Compute 'elEst'\n",
    "            elEst = np.array([a + b*c + d*e + f*g + h*i + j*k\n",
    "                              for a, b, c, d, e, f, g, h, i, j, k\n",
    "                              in zip(elIal, elICS, elS, elICT, elT, elICA, elA, elICB, elB, elICC, elC)])\n",
    "\n",
    "            # Store the results\n",
    "            elInterpolants[key] = (elIal, elICS, elICT, elICA, elICB, elICC, elEst)\n",
    "\n",
    "        Data, Estimate, Coefficients, CoefficientsUsed = {}, {}, {}, {}\n",
    "        for kcombo in AAdata.keys():\n",
    "            AAdata[kcombo][\"C0\"] = aaInterpolants[kcombo][0]\n",
    "            AAdata[kcombo][\"CS\"] = aaInterpolants[kcombo][1]\n",
    "            AAdata[kcombo][\"CT\"] = aaInterpolants[kcombo][2]\n",
    "            AAdata[kcombo][\"CA\"] = aaInterpolants[kcombo][3]\n",
    "            AAdata[kcombo][\"CB\"] = aaInterpolants[kcombo][4]\n",
    "            AAdata[kcombo][\"CC\"] = aaInterpolants[kcombo][5]\n",
    "            AAdata[kcombo][\"Estimate\"] = aaInterpolants[kcombo][6]\n",
    "            Elsedata[kcombo][\"C0\"] = elInterpolants[kcombo][0]\n",
    "            Elsedata[kcombo][\"CS\"] = elInterpolants[kcombo][1]\n",
    "            Elsedata[kcombo][\"CT\"] = elInterpolants[kcombo][2]\n",
    "            Elsedata[kcombo][\"CA\"] = elInterpolants[kcombo][3]\n",
    "            Elsedata[kcombo][\"CB\"] = elInterpolants[kcombo][4]\n",
    "            Elsedata[kcombo][\"CC\"] = elInterpolants[kcombo][5]\n",
    "            Elsedata[kcombo][\"Estimate\"] = elInterpolants[kcombo][6]\n",
    "\n",
    "            # Combine, sort, and extract TotData\n",
    "            TotData = pd.concat([AAdata[kcombo], Elsedata[kcombo]]).sort_values(by=[\"Order\"])\n",
    "            Coefficients[kcombo] = TotData\n",
    "            Estimate[kcombo] = TotData[\"Estimate\"]\n",
    "    \n",
    "            # Extract coefficients into a DataFrame\n",
    "            coefnames = [\"Intercept\", \"Coef S\", \"Coef T\", \"Coef A\", \"Coef B\", \"Coef C\"]\n",
    "            coefdata = [TotData[col].values for col in [\"C0\", \"CS\", \"CT\", \"CA\", \"CB\", \"CC\"]]\n",
    "            CoefficientsUsed[kcombo] = pd.DataFrame(np.array(coefdata).T, columns=coefnames)\n",
    "\n",
    "        # Estimating EMLR\n",
    "        def EMLR_Estimate(Equations, DesiredVariables, OutputCoordinates={}, PredictorMeasurements={}, UDict={}, DUDict={}, Coefficients={}, **kwargs):\n",
    "            EMLR, varnames, EqM = {}, [], []\n",
    "            \n",
    "            for dv in DesiredVariables:\n",
    "                # Fetch LIR data and process into grid arrays\n",
    "                LIR_data = fetch_data([dv])\n",
    "                grid_names = ['UDepth', 'USal', 'Eqn', 'RMSE']\n",
    "                UGridArray = pd.DataFrame(\n",
    "                    [np.nan_to_num([LIR_data[3][i][c][b][a] for a in range(16) for b in range(11) for c in range(8)]) for i in range(4)]\n",
    "                ).T\n",
    "                UGridArray.columns = grid_names\n",
    "                UGridPoints, UGridValues = (UGridArray['UDepth'], UGridArray['USal'], UGridArray['Eqn']), UGridArray['RMSE']\n",
    "        \n",
    "                for eq in range(len(Equations)):\n",
    "                    varnames.append(dv + str(Equations[eq]))\n",
    "                    EM = []\n",
    "                    eq_str = str(Equations[eq])\n",
    "                    eq_repeated = [Equations[eq]] * len(PredictorMeasurements['salinity'])\n",
    "                    UGridPointsOut = (OutputCoordinates['depth'], PredictorMeasurements['salinity'], eq_repeated)\n",
    "                    emlr = griddata(UGridPoints, UGridValues, UGridPointsOut, method='linear')\n",
    "                    combo = f\"{dv}{eq_str}\"\n",
    "                    Coefs = {k: np.nan_to_num(np.array(Coefficients[combo][k])) for k in [\"C0\", \"CS\", \"CT\", \"CA\", \"CB\", \"CC\"]}\n",
    "                    uncdfs, duncdfs = UDict[combo], DUDict[combo]\n",
    "                    keys = uncdfs.columns.to_numpy()\n",
    "                    USu, UTu, UAu, UBu, UCu = [np.nan_to_num(uncdfs[key].fillna(0).astype(float)) for key in keys]\n",
    "                    DUSu, DUTu, DUAu, DUBu, DUCu = [np.nan_to_num(duncdfs[key].fillna(0).astype(float)) for key in keys]\n",
    "                    USu2, UTu2, UAu2, UBu2, UCu2 = [np.nan_to_num(uncdfs[key].fillna(-9999).astype(float)) for key in keys]\n",
    "                    DUSu2, DUTu2, DUAu2, DUBu2, DUCu2 = [np.nan_to_num(duncdfs[key].fillna(-9999).astype(float)) for key in keys]\n",
    "            \n",
    "                    C0u2 = Coefs[\"C0\"] * 0\n",
    "                    Csum, DCsum = [], []\n",
    "                    \n",
    "                    for cucombo in range(len(Coefs[\"CS\"])):\n",
    "    \n",
    "                        s1 = (Coefs[\"CS\"][cucombo]*USu[cucombo])**2\n",
    "                        t1 = (Coefs[\"CT\"][cucombo]*UTu[cucombo])**2\n",
    "                        a1 = (Coefs[\"CA\"][cucombo]*UAu[cucombo])**2\n",
    "                        b1 = (Coefs[\"CB\"][cucombo]*UBu[cucombo])**2\n",
    "                        c1 = (Coefs[\"CC\"][cucombo]*UCu[cucombo])**2\n",
    "                        sum2 = s1+t1+a1+b1+c1\n",
    "                        ds1 = (Coefs[\"CS\"][cucombo]*DUSu[cucombo])**2\n",
    "                        dt1 = (Coefs[\"CT\"][cucombo]*DUTu[cucombo])**2\n",
    "                        da1 = (Coefs[\"CA\"][cucombo]*DUAu[cucombo])**2\n",
    "                        db1 = (Coefs[\"CB\"][cucombo]*DUBu[cucombo])**2\n",
    "                        dc1 = (Coefs[\"CC\"][cucombo]*DUCu[cucombo])**2\n",
    "                        dsum2 = ds1+dt1+da1+db1+dc1\n",
    "                        \n",
    "                        uncestimate = (sum2 - dsum2 + emlr[cucombo]**2)**0.5\n",
    "                        EM.append(uncestimate)            \n",
    "                    EqM.append(EM)\n",
    "            \n",
    "            EqM2 = []\n",
    "            for i in EqM:\n",
    "                UncertEst = np.array(i)\n",
    "                UncertEst = UncertEst.astype('float')\n",
    "                UncertEst[USu2==-9999]=['nan']\n",
    "                if Equations[eq] == 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8:\n",
    "                    UncertEst[UTu2==-9999]=['nan']\n",
    "                if Equations[eq] == 1 | 2 | 5 | 6 | 9 | 10 | 13 | 14:\n",
    "                    UncertEst[UAu2==-9999]=['nan']\n",
    "                if Equations[eq] == 1 | 3 | 5 | 7 | 9 | 11 | 13 | 15:\n",
    "                    UncertEst[UBu2==-9999]=['nan']\n",
    "                if Equations[eq] == 1 | 2 | 3 | 4 | 9 | 10 | 11 | 12:\n",
    "                    UncertEst[UCu2==-9999]=['nan']\n",
    "                EqM2.append(UncertEst)\n",
    "            for key in range(0, len(varnames)):\n",
    "                EMLR[varnames[key]] = EqM2[key]\n",
    "                EMLR = pd.DataFrame(EMLR)\n",
    "                \n",
    "            return EMLR\n",
    "\n",
    "        Uncerts = EMLR_Estimate(Equations, DesiredVariables, OutputCoordinates, PredictorMeasurements, unc_combo_dict, dunc_combo_dict, Coefficients=Coefficients)\n",
    "        return Estimate, Uncerts, CoefficientsUsed # PredictorMeasurements: Dictionary, Estimate: Dictionary, \n",
    "\n",
    "    # Uncertainties: pd DataFrame, DUncertainties: pd DataFrame, EMLR:list\n",
    "    Est_pre, Uncertainties, CoefficientsUsed = preprocess_interpolate(\n",
    "        DesiredVariables, \n",
    "        Equations, \n",
    "        EstDates, \n",
    "        VerboseTF, \n",
    "        C, \n",
    "        PredictorMeasurements, \n",
    "        Uncertainties_pre, \n",
    "        DUncertainties_pre\n",
    "    )\n",
    "    YouHaveBeenWarnedCanth = False\n",
    "        \n",
    "    def SimpleCantEstimateLR(EstDates, longitude, latitude, depth):\n",
    "        # Load interpolation points and values\n",
    "        CantIntPoints = pd.read_csv('SimpleCantEstimateLR_full.csv')\n",
    "        pointsi = (\n",
    "            CantIntPoints['Int_long'] * 0.25,\n",
    "            CantIntPoints['Int_lat'],\n",
    "            CantIntPoints['Int_depth'] * 0.025,\n",
    "        )\n",
    "        values = CantIntPoints['values']\n",
    "\n",
    "        # Scale input coordinates\n",
    "        pointso = (\n",
    "            np.array(longitude) * 0.25,\n",
    "            np.array(latitude),\n",
    "            np.array(depth) * 0.025,\n",
    "        )\n",
    "\n",
    "        # Interpolate and compute Cant2002\n",
    "        Cant2002 = griddata(pointsi, values, pointso, method='linear')\n",
    "\n",
    "        # Adjust for estimation dates\n",
    "        CantMeas = [\n",
    "            c * math.exp(0.018989 * (date - 2002)) for c, date in zip(Cant2002, EstDates)\n",
    "        ]\n",
    "\n",
    "        return CantMeas, Cant2002\n",
    "   \n",
    "    Cant_adjusted = {}\n",
    "    combos2 = list(Est_pre.keys())\n",
    "    values2 = list(Est_pre.values())\n",
    "\n",
    "    if \"EstDates\" in kwargs and (\"DIC\" in DesiredVariables or \"pH\" in DesiredVariables):      \n",
    "        if not YouHaveBeenWarnedCanth:\n",
    "            if VerboseTF:\n",
    "                print(\"Estimating anthropogenic carbon for PyESPER_NN.\")\n",
    "            longitude = np.mod(OutputCoordinates[\"longitude\"], 360)\n",
    "            latitude = np.array(OutputCoordinates[\"latitude\"])\n",
    "            depth = np.array(OutputCoordinates[\"depth\"])\n",
    "            Cant, Cant2002 = SimpleCantEstimateLR(EstDates, longitude, latitude, depth)\n",
    "            YouHaveBeenWarnedCanth = True\n",
    "        for combo, a in zip(combos2, values2):\n",
    "            dic = []\n",
    "            if combo.startswith(\"DIC\"):\n",
    "                for vala, Canta, Cant2002a in zip(a, Cant, Cant2002):\n",
    "                    if math.isnan(vala): \n",
    "                        dic.append(\"nan\")\n",
    "                    else:\n",
    "                        dic.append(vala + Canta - Cant2002a)\n",
    "            else:\n",
    "                dic = list(a)\n",
    "            Cant_adjusted[combo] = dic\n",
    "                 \n",
    "        if \"pH\" in DesiredVariables:\n",
    "            print('pH is detected')\n",
    "            warning = []\n",
    "            for combo, values in zip(combos2, values2):\n",
    "                if combo.startswith(\"pH\"):\n",
    "                    salinity = PredictorMeasurements[\"salinity\"]\n",
    "                    PM_pH = {'salinity': salinity}\n",
    "                    eq = [16]\n",
    "                    alkest, _, _ = preprocess_interpolate(\n",
    "                        [\"TA\"], eq, EstDates, ['False'], C, PM_pH, Uncertainties_pre, DUncertainties_pre\n",
    "                    )\n",
    "                    EstAlk = np.array(alkest[\"TA16\"])\n",
    "                    EstSi = EstP = [0] * len(EstAlk)\n",
    "                    Pressure = sw.pres(OutputCoordinates[\"depth\"], OutputCoordinates[\"latitude\"])\n",
    "                    Est = np.array(values)\n",
    "\n",
    "                    # CO2SYS calculations\n",
    "                    Out = pyco2.sys(\n",
    "                        par1=EstAlk, par2=Est, par1_type=1, par2_type=3, salinity=salinity,\n",
    "                        temperature=PredictorMeasurements[\"temperature\"], temperature_out=PredictorMeasurements[\"temperature\"],\n",
    "                        pressure=Pressure, pressure_out=Pressure, total_silicate=EstSi, total_phosphate=EstP, opt_total_borate=2\n",
    "                    )\n",
    "                    DICadj = Out[\"dic\"] + Cant - Cant2002\n",
    "                    OutAdj = pyco2.sys(\n",
    "                        par1=EstAlk, par2=DICadj, par1_type=1, par2_type=2, salinity=salinity,\n",
    "                        temperature=PredictorMeasurements[\"temperature\"], temperature_out=PredictorMeasurements[\"temperature\"],\n",
    "                        pressure=Pressure, pressure_out=Pressure, total_silicate=EstSi, total_phosphate=EstP, opt_total_borate=2\n",
    "                    )\n",
    "                    pHadj = OutAdj[\"pH\"]\n",
    "\n",
    "                    # Check for convergence warnings\n",
    "                    if any(np.isnan(pHadj)):\n",
    "                        warning_message = (\n",
    "                            \"Warning: CO2SYS took >20 iterations to converge. The corresponding estimate(s) will be NaN. \"\n",
    "                            \"This typically happens when ESPER_LIR is poorly suited for estimating water with the given properties \"\n",
    "                            \"(e.g., very high or low salinity or estimates in marginal seas).\"\n",
    "                        )\n",
    "                        warning.append(warning_message)\n",
    "                else:\n",
    "                    pHadj = np.array(values)\n",
    "\n",
    "                Cant_adjusted[combo] = pHadj.tolist()\n",
    "\n",
    "            # Print warnings if any\n",
    "            if warning:\n",
    "                print(warning[0])\n",
    "                \n",
    "    elif \"EstDates\" not in kwargs and (\"DIC\" or \"pH\" in DesiredVariables) and VerboseTF == True and YouHaveBeenWarnedCanth == False:\n",
    "        print(\"Warning: DIC or pH is a requested output but the user did not provide dates for the desired estimates.  The estimates \"\n",
    "              \"will be specific to 2002.0 unless the optional EstDates input is provided (recommended).\")\n",
    "        YouHaveBeenWarnedCanth = True\n",
    "\n",
    "    if kwargs.get(\"pHCalcTF\") == True and \"pH\" in DesiredVariables:\n",
    "        if VerboseTF == True:\n",
    "            print(\"Recalculating the pH to be appropriate for pH values calculated from TA and DIC.\")\n",
    "        for combo in range(0, len(combos2)):\n",
    "            if combos2[combo].startswith(\"pH\"):\n",
    "                pH_adjcalc_Est = []\n",
    "                pH_adjcalc = values2[combo]\n",
    "                for v in pH_adjcalc:\n",
    "                    pH_adjcalc_Est.append((pH_adjcalc[v]+0.3168)/1.0404)\n",
    "            Cant_adjusted[combos2[combo]] = pH_adjcalc_Est\n",
    "\n",
    "    combos3 = Cant_adjusted.keys()\n",
    "    values3 = Cant_adjusted.values()\n",
    "\n",
    "    Estimates = {}\n",
    "    k2 = list(combos2)\n",
    "    v2 = list(values2)\n",
    "    k3 = list(combos3)\n",
    "    v3 = list(values3)\n",
    "    for keys2 in range(0, len(k2)):\n",
    "        ar2 = np.array(v2[keys2])\n",
    "        for keys3 in range(0, len(k3)):\n",
    "            ar2[k2[keys2] == k3[keys3]] = v3[keys3]\n",
    "            \n",
    "        Estimates[k2[keys2]] = ar2\n",
    "        Estimates = pd.DataFrame(Estimates)\n",
    "       \n",
    "    toc = time.perf_counter()\n",
    "    print(f\"PyESPER_LIR took {toc - tic:0.4f} seconds, or {(toc-tic)/60:0.4f} minutes to run\")    \n",
    "    \n",
    "    return Estimates, Uncertainties, CoefficientsUsed        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4934fa54-d3d6-443b-b002-4ff60c66cd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PyESPER_NN(DesiredVariables, Path, OutputCoordinates={}, PredictorMeasurements={}, **kwargs):\n",
    "\n",
    "    \"\"\"\n",
    "    Python interpretation of ESPER_NNv1.1\n",
    "\n",
    "    Empirical Seawater Property Estimation Routines: Estimates seawater properties and estimate uncertainty from combinations of other parameter\n",
    "    measurements.  PYESPER_NN refers specifically to code that uses neural networks as opposed to collections of interpolated linear regressions\n",
    "    (LIRs), and Python rather than MATLAB coding languages.  \n",
    "\n",
    "    Reserved for version update notes: (no updates, first version)\n",
    "  \n",
    "    Documentation and citations:\n",
    "    LIARv1: Carter et al., 2016, doi: 10.1002/lom3.10087\n",
    "    LIARv2, LIPHR, LINR citation: Carter et al., 2018, https://doi.org/10.1002/lom3.10232\n",
    "    LIPR, LISIR, LIOR, first described/used: Carter et al., 2021, https://doi.org/10.1029/2020GB006623\n",
    "    LIRv3 and ESPER_NN (ESPERv1.1): Carter, 2021, https://10.5281/ZENODO.5512697\n",
    "\n",
    "    PyESPER_NN is a Python replicate of ESPER_NN:\n",
    "    Carter et al. 2021: https://doi.org/10.1002/lom3.10461\n",
    "    ESPER_NN is inspired by CANYON-B, which also uses neural networks: \n",
    "    Bittig et al. 2018: https://doi.org/10.3389/fmars.2018.00328\n",
    "\n",
    "    This function needs numpy, scipy, pandas, math, matplotlib, importlib, and statistics packages. The seawater package is required if \n",
    "    measurements are provided in molar units or if potential temperature or AOU are needed but not provided by the user.  Scale differences from \n",
    "    TEOS-10 are a negligible component of alkalinity estimate error. PyCO2SYS is required if pH on the total scale is a desired output variable. \n",
    " \n",
    "    ****************************************************************************\n",
    "    Input/Output dimensions:\n",
    "    ............................................................................\n",
    "    p:   Integer number of desired property estimate types (e.g., TA, pH, NO3-)\n",
    "    n:   Integer number of desired estimate locations\n",
    "    e:   Integer number of equations used at each location\n",
    "    y:   Integer number of parameter measurement types provided by the user.\n",
    "    n*e: Total number of estimates returned as an n by e array\n",
    "    ****************************************************************************\n",
    "   \n",
    "    Required Inputs:\n",
    "   \n",
    "    DesiredVariables: (required 1 by p list, where p specifies the desired variable(s) in string format):\n",
    "        List elements specify which variables will be returned. Excepting unitless pH, all outputs are in micromol per kg seawater. Naming of list\n",
    "        elements must be exactly as demonstrated below (exs: [\"TA\"], [\"DIC\", \"phosphate\", \"oxygen\"]).\n",
    "\n",
    "        Desired Variable:                    | List Element Name (String Format):\n",
    "        *********************************************************************\n",
    "        Total Titration Seawater Alkalinity  | TA\n",
    "        Total Dissolved Inorganic Carbon     | DIC\n",
    "        in situ pH on the total scale        | pH\n",
    "        Phosphate                            | phosphate\n",
    "        Nitrate                              | nitrate\n",
    "        Silicate                             | silicate\n",
    "        Dissolved Oxygen (O2)                | oxygen\n",
    "\n",
    "    Path (required string):\n",
    "        Path directing Python to the location of saved/downloaded neural net files on the user's computer (ex: '/Users/lara/Documents/Python'). \n",
    "\n",
    "    OutputCoordinates (required n by 3 dictionary, where n are the number of desired estimate locations and the three dictionary keys are \n",
    "    longitude, latitude, and depth): \n",
    "        Coordinates at which estimates are desired.  The keys should be longitude (degrees E), latitude (degrees N), and positive integer depth  \n",
    "        (m), with dictionary keys named 'longitude', 'latitude', and 'depth' (ex: OutputCoordinates={\"longitude\": [0, 180, -50, 10], \"latitude\": \n",
    "        [85, -20, 18, 0.5], \"depth\": [10, 1000, 0, 0]} or OutputCoordinates={'longitude': long, 'latitude': lat, 'depth': depth} when referring \n",
    "        to a set of predefined lists or numpy arrays of latitude, longitude, and depth information.\n",
    " \n",
    "    PredictorMeasurements (required n by y dictionary, where n are the number of desired estimate locations and y are the dictionary keys  \n",
    "    representing each possible input): \n",
    "       Parameter measurements that will be used to estimate desired variables. Concentrations should be expressed as micromol per kg seawater  \n",
    "       unless PerKgSwTF is set to false in which case they should be expressed as micromol per L, temperature should be expressed as degrees C, and \n",
    "       salinity should be specified with the unitless convention.  NaN inputs are acceptable, but will lead to NaN estimates for any equations that \n",
    "       depend on that parameter.The key order (y columns) is arbitrary, but naming of keys must adhere to  the following convention (ex: \n",
    "       PredictorMeasurements={\"salinity\":[35, 34.1, 32, 33], \"temperature\": [0.1, 10, 0.5, 2], \"oxygen\": [202.3, 214.7, 220.5, 224.2]} or \n",
    "       PredictorMeasurements={'salinity': sal, 'temperature': temp, 'phosphate': phos, 'nitrate': nitr} when referring to predefined lists or \n",
    "       numpy arrays of measurements):\n",
    "\n",
    "       Input Parameter:                       | Dictionary Key Name:\n",
    "       **********************************************************************\n",
    "       Salinity                               | salinity\n",
    "       Temperature                            | temperature\n",
    "       Phosphate                              | phosphate\n",
    "       Nitrate                                | nitrate\n",
    "       Silicate                               | silicate\n",
    "       O2                                     | oxygen   \n",
    "       **********************************************************************\n",
    "       \n",
    "    Optional inputs:  All remaining inputs must be specified as sequential input argument pairs (e.g. \"EstDates\"=EstDates when referring to a \n",
    "    predefined list of dates, 'Equations'=[1:16], pHCalcTF=True, etc.)\n",
    "\n",
    "    EstDates (optional but recommended n by 1 list or 1 by 1 value, default 2002.0): \n",
    "        A list of decimal dates for the estimates (e.g. July 1 2020 would be \"2020.5\").  If only a single date is supplied that value is used\n",
    "        for all estimates.  It is highly recommended that date(s) be provided for estimates of DIC and pH.  This version of the code will accept \n",
    "        1 by n inputs as well.\n",
    "    \n",
    "    Equations (optional 1 by e list, default [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]): \n",
    "        List indicating which equations will be used to estimate desired variables. If [] is input or the input is not specified then all 16 \n",
    "        equations will be used.\n",
    "     \n",
    "        (S=salinity, T=temperature, oxygen=dissolved oxygen molecule... see 'PredictorMeasurements' for units).\n",
    "        ...............................................................\n",
    "        Output Equation Key (See below for explanation of A, B, and C):\n",
    "        1.  S, T, A, B, C\n",
    "        2.  S, T, A, C\n",
    "        3.  S, T, B, C\n",
    "        4.  S, T, C\n",
    "        5.  S, T, A, B\n",
    "        6.  S, T, A\n",
    "        7.  S, T, B\n",
    "        8.  S, T\n",
    "        9.  S, A, B, C\n",
    "        10. S, A, C\n",
    "        11. S, B, C\n",
    "        12. S, C\n",
    "        13. S, A, B\n",
    "        14. S, A\n",
    "        15. S, B\n",
    "        16. S\n",
    "    \n",
    "        DesiredVar   | A             B             C\n",
    "        _____________|_____________________________________\n",
    "        TA           | nitrate       oxygen        silicate\n",
    "        DIC          | nitrate       oxygen        silicate\n",
    "        pH           | nitrate       oxygen        silicate\n",
    "        phosphate    | nitrate       oxygen        silicate\n",
    "        nitrate      | phosphate     oxygen        silicate\n",
    "        silicate     | phosphate     oxygen        nitrate\n",
    "        O2           | phosphate     nitrate       silicate\n",
    "    \n",
    "    MeasUncerts (Optional n by y dictionary or 1 by y dictionary, default: [0.003 S, 0.003 degrees C T or potential temperature, 2% phosphate, \n",
    "    2% nitrate, 2% silicate, 1% AOU or O2]): \n",
    "        Dictionary of measurement uncertainties (see 'PredictorMeasurements' for units). Providing these estimates will improve PyESPER_NN\n",
    "        estimate uncertainties. Measurement uncertainties are a small part of PyESPER_NN estimate uncertainties for WOCE-quality measurements. \n",
    "        However, estimate uncertainty scales with measurement uncertainty, so it is recommended that measurement uncertainties be specified for \n",
    "        sensor measurements.  If this optional input argument is not provided, the default WOCE-quality uncertainty is assumed.  If a 1 by y array \n",
    "        is provided then the uncertainty estimates are assumed to apply uniformly to all input parameter measurements. Uncertainties should be \n",
    "        presented with the following naming convention:\n",
    "\n",
    "       Input Uncertainties:                   | Key Name:\n",
    "       ********************************************************\n",
    "       Salinity                               | sal_u\n",
    "       Temperature                            | temp_u\n",
    "       Phosphate                              | phosphate_u\n",
    "       Nitrate                                | nitrate_u\n",
    "       Silicate                               | silicate_u\n",
    "       O2                                     | oxygen_u\n",
    "       \n",
    "    pHCalcTF (Optional boolean, default false): \n",
    "        If set to true, PyESPER will recalculate the pH to be a better estimate of what the seawater pH value would be if calculated from TA and\n",
    "        DIC instead of measured with purified m-cresol dye. This is arguably also a better estimate of the pH that would be obtained from pre-2011\n",
    "        measurements with impure dyes.  See the LIPHR paper for details\n",
    "    \n",
    "    PerKgSwTF (Optional boolean, default true): \n",
    "        Many sensors provide measurements in micromol per L (molarity) instead of micromol per kg seawater. Indicate false if provided\n",
    "        measurements are expressed in molar units (concentrations must be micromol per L if so).  Outputs will remain in molal units regardless.\n",
    "    \n",
    "    VerboseTF (Optional boolean, default true): \n",
    "        Setting this to false will reduce the number of updates, warnings, and errors printed by PyESPER_NN. And additional step can be taken before \n",
    "        before executing the PyESPER_NN function (see below) that will further reduce updates, warnings, and errors, if desired. \n",
    "        \n",
    "    *************************************************************************\n",
    "    Outputs:\n",
    " \n",
    "    Estimates: \n",
    "        A n by e pandas DataFrame of estimates specific to the coordinates and parameter measurements provided as inputs.  Units are micromoles  \n",
    "        per kg (equivalent to the deprecated microeq per kg seawater). Column names are the unique desired variable-equation combinations requrested by \n",
    "        the user. \n",
    "\t\n",
    "     Uncertainties: \n",
    "        A n by e dictionary of uncertainty estimates specific to the coordinates, parameter measurements, and parameter uncertainties provided.\n",
    "        Units are micromoles per kg (equivalent to the deprecated microeq per kg seawater). Column names are the unique desired variable-equation \n",
    "        combinations requrested by the user. \n",
    "        \n",
    "    *************************************************************************\n",
    "    Missing data: should be indicated with a nan.  A nan coordinate will yield nan estimates for all equations at that coordinate.  A nan\n",
    "    parameter value will yield NaN estimates for all equations that require that parameter.\n",
    " \n",
    "    *************************************************************************\n",
    "    Please send questions or related requests about PyESPER to lmdias@uw.edu.\n",
    "    ************************************************************************* \n",
    "    \"\"\"\n",
    "\n",
    "    import numpy as np\n",
    "    import time\n",
    "    from scipy.interpolate import griddata\n",
    "    import seawater as sw\n",
    "    import PyCO2SYS as pyco2\n",
    "    import pandas as pd\n",
    "    import math\n",
    "    from scipy.io import loadmat\n",
    "    import matplotlib.path as mpltPath\n",
    "    import importlib\n",
    "    from statistics import mean\n",
    "    \n",
    "    tic = time.perf_counter()\n",
    "    \n",
    "    # Checking for presence of required input parameters and raising a custom error message if needed\n",
    "    class CustomError(Exception):\n",
    "        pass\n",
    "        \n",
    "    required_coords = (\"longitude\", \"latitude\", \"depth\")\n",
    "    for coord_name in required_coords:\n",
    "        if coord_name not in OutputCoordinates:\n",
    "            raise CustomError(f\"Warning: Missing {coord_name} in OutputCoordinates.\")\n",
    "            \n",
    "    if \"salinity\" not in PredictorMeasurements: \n",
    "        raise CustomError(\"Warning: Missing salinity measurements. Salinity is a required input.\")\n",
    "            \n",
    "    if \"oxygen\" in PredictorMeasurements and \"temperature\" not in PredictorMeasurements:\n",
    "        raise CustomError(\"Warning: Missing temperature measurements. Temperature is required when oxygen is provided.\")\n",
    "\n",
    "    # Checking the sanity of input values and printing warnings for erroneous input\n",
    "    if \"temperature\" in PredictorMeasurements:\n",
    "        if any(t < -5 or t > 50 for t in PredictorMeasurements[\"temperature\"]):\n",
    "               print(\"Warning: Temperatures less than -5 C or greater than 100 C have been found. PyESPER is not intended for seawater with these properties. Note that PyESPER expects temperatures in Centigrade.\")\n",
    "                \n",
    "    if any(s < 5 or s > 50 for s in PredictorMeasurements[\"salinity\"]):\n",
    "        print(\"Warning: Salinities less than 5 or greater than 50 have been found. ESPER is not intended for seawater with these properties.\")\n",
    "        \n",
    "    if any(d < 0 for d in OutputCoordinates[\"depth\"]):\n",
    "        print(\"Warning: Depth can not be negative.\")\n",
    "        \n",
    "    if any(l > 90 for l in OutputCoordinates[\"latitude\"]):\n",
    "        print(\"Warning: A latitude >90 deg (N or S) has been detected. Verify latitude is entered correctly as an input.\")\n",
    "    \n",
    "    # Checking for commonly used missing data indicator flags. Consider adding your commonly used flags here.  \n",
    "    if any(l == -9999 or l == -9 or l == -1e20 for l in OutputCoordinates[\"latitude\"]):\n",
    "           print(\"Warning: A common non-NaN missing data indicator (e.g., -999, -9, -1e20) was detected in the input measurements provided. Missing data should be replaced with NaNs. Otherwise, ESPER will interpret your inputs at face value and give terrible estimates.\")  \n",
    "\n",
    "    # Check and define Equations based on user-defined kwargs, or use default values\n",
    "    Equations = kwargs.get(\"Equations\", list(range(1, 17)))\n",
    "\n",
    "    # Reading dimensions of user input\n",
    "    n = max(len(v) for v in OutputCoordinates.values()) # number of rows out\n",
    "    e = len(Equations) # number of Equations\n",
    "    p = len(DesiredVariables) # number of Variables\n",
    "\n",
    "    # Checking kwargs for presence of VerboseTF and defining defaults as needed\n",
    "    VerboseTF = kwargs.get(\"VerboseTF\", True)\n",
    "        \n",
    "    # Set EstDates based on kwargs, defaulting to 2002.0 if not provided\n",
    "    if \"EstDates\" in kwargs:\n",
    "        d = np.array(kwargs[\"EstDates\"])\n",
    "        EstDates = (\n",
    "            [item for sublist in [kwargs[\"EstDates\"]] * (n + 1) for item in sublist]\n",
    "            if len(d) != n else list(d)\n",
    "        )\n",
    "    else:\n",
    "        EstDates = [2002.0] * n\n",
    "\n",
    "    # Bookkeeping coordinates\n",
    "    C = {}\n",
    "    longitude = np.array(OutputCoordinates[\"longitude\"])\n",
    "    longitude[longitude > 360] = np.remainder(longitude[longitude > 360], 360)\n",
    "    longitude[longitude < 0] = longitude[longitude<0] + 360\n",
    "    C[\"longitude\"] = longitude\n",
    "    C[\"latitude\"] = OutputCoordinates[\"latitude\"]\n",
    "    C[\"depth\"] = OutputCoordinates[\"depth\"]  \n",
    "\n",
    "    # Define or read in PerKgSwTF\n",
    "    PerKgSwTF = kwargs.get(\"PerKgSwTF\", True)\n",
    "\n",
    "    # Reading in MeasUncerts, if user-defined uncertainties are present in kwargs. Interpreting these, or defining measurement and\n",
    "    # default uncertainties, if absent from kwargs.\n",
    "    MeasUncerts_processed, DefaultUAll = {}, {}\n",
    "    if \"MeasUncerts\" in kwargs:  \n",
    "        MeasUncerts=kwargs.get(\"MeasUncerts\")\n",
    "        if max(len(v) for v in MeasUncerts.values()) != n:\n",
    "            if min(len(v) for v in MeasUncerts.values()) != 1: \n",
    "                raise CustomError(\"MeasUncerts must be undefined, a vector with the same number of elements as \\\n",
    "                PredictorMeasurements has columns, or a matrix of identical dimension to PredictorMeasurements.\")\n",
    "        if len(MeasUncerts) != len(PredictorMeasurements):\n",
    "            print(\"Warning: There are different numbers of columns of input uncertainties and input measurements.\")\n",
    "               \n",
    "         # Default salinity uncertainties\n",
    "        sal_u = np.array(MeasUncerts.get(\"sal_u\", [0.003]))\n",
    "        sal_u = np.tile(sal_u, n) if len(sal_u) < n else sal_u\n",
    "        sal_defu = np.tile(0.003, n)\n",
    "        \n",
    "        temp_u = np.array(MeasUncerts.get(\"temp_u\", [0.003])) if \"temp_u\" in MeasUncerts or \"temperature\" in PredictorMeasurements else np.tile(\"nan\", n)\n",
    "        temp_u = np.tile(temp_u, n) if len(temp_u) < n else temp_u\n",
    "        temp_defu = np.tile(0.003, n) if \"temp_u\" in MeasUncerts or \"temperature\" in PredictorMeasurements else np.tile(0, n)\n",
    "\n",
    "        def process_uncert(param, default_factor):\n",
    "            if f\"{param}_u\" in MeasUncerts:\n",
    "                result = np.array(MeasUncerts[f\"{param}_u\"])\n",
    "                result = np.tile(result, n) if len(result) < n else result\n",
    "            else:\n",
    "                result = (\n",
    "                    np.array([i * default_factor for i in PredictorMeasurements[param]])\n",
    "                    if param in PredictorMeasurements else np.tile(\"nan\", n)\n",
    "                )\n",
    "            dresult = result if param not in PredictorMeasurements else np.array([i * default_factor for i in PredictorMeasurements[param]])\n",
    "            MeasUncerts_processed[f\"{param}_u\"] = result\n",
    "            DefaultUAll[f\"{param}_defu\"] = dresult\n",
    "\n",
    "        # Process all parameters with their respective default factors\n",
    "        for param, default_factor in [(\"phosphate\", 0.02), (\"nitrate\", 0.02), (\"silicate\", 0.02), (\"oxygen\", 0.01)]:\n",
    "            process_uncert(param, default_factor)\n",
    "\n",
    "        # Extract processed uncertainties\n",
    "        phosphate_u, phosphate_defu = np.array(MeasUncerts_processed[\"phosphate_u\"]), np.array(DefaultUAll[\"phosphate_defu\"])\n",
    "        nitrate_u, nitrate_defu = np.array(MeasUncerts_processed[\"nitrate_u\"]), np.array(DefaultUAll[\"nitrate_defu\"])\n",
    "        silicate_u, silicate_defu = np.array(MeasUncerts_processed[\"silicate_u\"]), np.array(DefaultUAll[\"silicate_defu\"])\n",
    "        oxygen_u, oxygen_defu = np.array(MeasUncerts_processed[\"oxygen_u\"]), np.array(DefaultUAll[\"oxygen_defu\"])\n",
    "                \n",
    "    else:\n",
    "        MeasUncerts = {}\n",
    "        sal_u = sal_defu = np.tile(0.003, n)\n",
    "\n",
    "        # Helper function to set uncertainties and default uncertainties\n",
    "        def default_uncert(param, factor):\n",
    "            if param in PredictorMeasurements:\n",
    "                result = np.array([i * factor for i in PredictorMeasurements[param]])\n",
    "            else:\n",
    "                result = np.tile(\"nan\", n)\n",
    "            return result\n",
    "\n",
    "        temp_u, temp_defu = (np.tile(0.003, n), np.tile(0.003, n)) if \"temperature\" in PredictorMeasurements else (np.tile(\"nan\", n), np.tile(0, n))\n",
    "\n",
    "        phosphate_u = phosphate_defu = default_uncert(\"phosphate\", 0.02)\n",
    "        nitrate_u = nitrate_defu = default_uncert(\"nitrate\", 0.02)\n",
    "        silicate_u = silicate_defu = default_uncert(\"silicate\", 0.02)\n",
    "        oxygen_u = oxygen_defu = default_uncert(\"oxygen\", 0.01)\n",
    "            \n",
    "    # Define the keys and corresponding variables for MeasUncerts\n",
    "    meas_uncerts_keys = [\"sal_u\", \"temp_u\", \"phosphate_u\", \"nitrate_u\", \"silicate_u\", \"oxygen_u\"]\n",
    "    meas_uncerts_values = [sal_u, temp_u, phosphate_u, nitrate_u, silicate_u, oxygen_u]\n",
    "\n",
    "    # Update MeasUncerts using a dictionary comprehension\n",
    "    MeasUncerts.update(dict(zip(meas_uncerts_keys, meas_uncerts_values)))\n",
    "\n",
    "    # Define the keys and corresponding variables for DefaultUAll\n",
    "    default_uall_keys = [\"sal_defu\", \"temp_defu\", \"phosphate_defu\", \"nitrate_defu\", \"silicate_defu\", \"oxygen_defu\"]\n",
    "    default_uall_values = [sal_defu, temp_defu, phosphate_defu, nitrate_defu, silicate_defu, oxygen_defu]\n",
    "\n",
    "    # Update DefaultUAll using a dictionary comprehension\n",
    "    DefaultUAll.update(dict(zip(default_uall_keys, default_uall_values)))\n",
    "       \n",
    "    keys = [\"sal_u\", \"temp_u\", \"phosphate_u\", \"nitrate_u\", \"silicate_u\", \"oxygen_u\"]\n",
    "    Uncerts = np.column_stack((sal_u, temp_u, phosphate_u, nitrate_u, silicate_u, oxygen_u))\n",
    "    Uncertainties_pre = pd.DataFrame(Uncerts, columns=keys) \n",
    "    DUncerts = np.column_stack((sal_defu, temp_defu, phosphate_defu, nitrate_defu, silicate_defu, oxygen_defu))\n",
    "    DUncertainties_pre = pd.DataFrame(DUncerts, columns=keys)\n",
    "\n",
    "    # This function is the primary function of the PyESPER_NN, which preprocesses all data and applies the saved neural networks to the input data\n",
    "    def preprocess_applynets(\n",
    "        DesiredVariables,\n",
    "        Equations, \n",
    "        EstDates, \n",
    "        VerboseTF,\n",
    "        C={}, \n",
    "        PredictorMeasurements={}, \n",
    "        Uncertainties={},\n",
    "        DUncertainties={}\n",
    "    ):\n",
    "\n",
    "        n = max(len(v) for v in C.values()) # number of rows out\n",
    "\n",
    "        # Organizing data thus far\n",
    "        order = list(range(n))\n",
    "        input_data = {\n",
    "            \"Order\": order,\n",
    "            \"Longitude\": C[\"longitude\"],\n",
    "            \"Latitude\": C[\"latitude\"],\n",
    "            \"Depth\": C[\"depth\"],\n",
    "            \"Salinity\": PredictorMeasurements[\"salinity\"],\n",
    "            \"Dates\": EstDates,\n",
    "            \"Salinity_u\": Uncertainties[\"sal_u\"],\n",
    "            \"Temperature_u\": Uncertainties[\"temp_u\"],\n",
    "            \"Phosphate_u\": Uncertainties[\"phosphate_u\"],\n",
    "            \"Nitrate_u\": Uncertainties[\"nitrate_u\"],\n",
    "            \"Silicate_u\": Uncertainties[\"silicate_u\"],\n",
    "            \"Oxygen_u\": Uncertainties[\"oxygen_u\"]\n",
    "        }\n",
    "    \n",
    "        if \"temperature\" in PredictorMeasurements:\n",
    "            input_data[\"Temperature\"] = PredictorMeasurements[\"temperature\"]\n",
    "        if \"phosphate\" in PredictorMeasurements:\n",
    "            input_data[\"Phosphate\"] = PredictorMeasurements[\"phosphate\"]\n",
    "        if \"nitrate\" in PredictorMeasurements:\n",
    "            input_data[\"Nitrate\"] = PredictorMeasurements[\"nitrate\"]\n",
    "        if \"silicate\" in PredictorMeasurements:\n",
    "            input_data[\"Silicate\"] = PredictorMeasurements[\"silicate\"]\n",
    "        if \"oxygen\" in PredictorMeasurements:\n",
    "            input_data[\"Oxygen\"] = PredictorMeasurements[\"oxygen\"]\n",
    "\n",
    "        InputAll = pd.DataFrame(input_data)\n",
    "        # created a dataframe with order stamp and dropped all nans from a replicate dataframe\n",
    "\n",
    "        # Printing a custom warning if temperature is absent but needed \n",
    "        if \"EstDates\" in kwargs and \"pH\" in DesiredVariables:\n",
    "            if \"temperature\" not in PredictorMeasurements:\n",
    "                print(\n",
    "                    \"Warning: Carbonate system calculations will be used to adjust the pH, but no temperature is \"\n",
    "                    \"specified so 10 C will be assumed. If this is a poor estimate for your region, consider supplying \"\n",
    "                    \"your own value in the PredictorMeasurements input.\"\n",
    "                )\n",
    "                Temperature = [10] * n\n",
    "            else:\n",
    "                Temperature = InputAll[\"Temperature\"]\n",
    "    \n",
    "            PredictorMeasurements[\"temperature\"] = Temperature\n",
    "            InputAll[\"temperature\"] = Temperature\n",
    "\n",
    "        # Beginning treatment of inputs and iterations \n",
    "        depth, latitude, salinity = np.array(C[\"depth\"]), np.array(C[\"latitude\"]), np.array(PredictorMeasurements[\"salinity\"])\n",
    "        temp = np.array(PredictorMeasurements[\"temperature\"]) if \"temperature\" in PredictorMeasurements else np.full(n, 10)\n",
    "        temp_sw = sw.ptmp(salinity, temp, sw.pres(depth, latitude), pr=0)\n",
    "        temperature_processed = [\n",
    "            \"{:.15g}\".format(\n",
    "                {3: 3.000000001, 4: 4.000000001, 5: 5.000000001, 6: 6.000000001}.get(t, 10 if t < -100 else t)\n",
    "            ) \n",
    "            for t in temp_sw\n",
    "        ]\n",
    "        if \"oxygen\" in PredictorMeasurements:\n",
    "            oxyg = np.array(PredictorMeasurements[\"oxygen\"])\n",
    "            oxyg_sw = sw.satO2(salinity, temp_sw)*44.6596 - (oxyg)\n",
    "        else: \n",
    "            oxyg_sw = np.tile(\"nan\", n)\n",
    "        for i in range(len(oxyg_sw)):\n",
    "            if oxyg_sw[i] != \"nan\" and -0.0001 < oxyg_sw[i] < 0.0001:\n",
    "                oxyg_sw[i] = 0\n",
    "        oxygen_processed = [\"{:.5g}\".format(o) if o != \"nan\" else o for o in oxyg_sw]\n",
    "        if \"phosphate\" in PredictorMeasurements:\n",
    "            phosphate_processed = np.array(PredictorMeasurements[\"phosphate\"])\n",
    "        else:\n",
    "            phosphate_processed = np.tile(\"nan\", n)\n",
    "        if \"nitrate\" in PredictorMeasurements:\n",
    "            nitrate_processed = np.array(PredictorMeasurements[\"nitrate\"])\n",
    "        else:\n",
    "            nitrate_processed = np.tile(\"nan\", n)\n",
    "        if \"silicate\" in PredictorMeasurements:\n",
    "            silicate_processed = np.array(PredictorMeasurements[\"silicate\"])\n",
    "        else: \n",
    "            silicate_processed = np.tile(\"nan\", n)\n",
    "    \n",
    "        if not PerKgSwTF:\n",
    "            densities = sw.dens(salinity, temperature_processed, sw.pres(depth, latitude)) / 1000\n",
    "            for nutrient in [\"phosphate\", \"nitrate\", \"silicate\"]:\n",
    "                if nutrient in PredictorMeasurements:\n",
    "                    globals()[f\"{nutrient}_processed\"] /= densities\n",
    "            \n",
    "        EqsString = [str(e) for e in Equations]\n",
    "    \n",
    "        NeededForProperty = pd.DataFrame({\n",
    "                 \"TA\": [1, 2, 4, 6, 5], \n",
    "                \"DIC\": [1, 2, 4, 6, 5], \n",
    "                \"pH\": [1, 2, 4, 6, 5],  \n",
    "                \"phosphate\": [1, 2, 4, 6, 5], \n",
    "                \"nitrate\": [1, 2, 3, 6, 5], \n",
    "                \"silicate\": [1, 2, 3, 6, 4], \n",
    "                \"oxygen\": [1, 2, 3, 4, 5]\n",
    "                })\n",
    "            \n",
    "        VarVec = pd.DataFrame({\n",
    "                \"1\": [1, 1, 1, 1, 1],\n",
    "                \"2\": [1, 1, 1, 0, 1],\n",
    "                \"3\": [1, 1, 0, 1, 1],\n",
    "                \"4\": [1, 1, 0, 0, 1],\n",
    "                \"5\": [1, 1, 1, 1, 0],\n",
    "                \"6\": [1, 1, 1, 0, 0],\n",
    "                \"7\": [1, 1, 0, 1, 0],\n",
    "                \"8\": [1, 1, 0, 0, 0],\n",
    "                \"9\": [1, 0, 1, 1, 1],\n",
    "                \"10\": [1, 0, 1, 0, 1],\n",
    "                \"11\": [1, 0, 0, 1, 1],\n",
    "                \"12\": [1, 0, 0, 0, 1],\n",
    "                \"13\": [1, 0, 1, 1, 0],\n",
    "                \"14\": [1, 0, 1, 0, 0],\n",
    "                \"15\": [1, 0, 0, 1, 0],\n",
    "                \"16\": [1, 0, 0, 0, 0],\n",
    "            })\n",
    "    \n",
    "        product, product_processed, name = [], [], []\n",
    "        need, precode, preunc = {}, {}, {}\n",
    "    \n",
    "        # Create a list of names and process products\n",
    "        replacement_map = {\n",
    "            \"0\": \"nan\",\n",
    "            \"1\": \"salinity\",\n",
    "            \"2\": \"temperature\",\n",
    "            \"3\": \"phosphate\",\n",
    "            \"4\": \"nitrate\",\n",
    "            \"5\": \"silicate\",\n",
    "            \"6\": \"oxygen\"\n",
    "        }\n",
    "\n",
    "        for d in DesiredVariables:\n",
    "            dv = NeededForProperty[d]\n",
    "            for e in EqsString:\n",
    "                eq = VarVec[e]\n",
    "                prename = d + e\n",
    "                name.append(prename)\n",
    "                product.append(eq * dv)\n",
    "                prodnp = np.array(eq * dv)\n",
    "\n",
    "                # Replace values using the mapping\n",
    "                processed = np.vectorize(lambda x: replacement_map.get(str(x), x))(prodnp)\n",
    "                need[prename] = processed\n",
    "                \n",
    "        for p in range(0, len(product)): # Same but for list of input values\n",
    "            prodnptile = np.tile(product[p], (n, 1)).astype(\"str\")\n",
    "\n",
    "            for v in range(0, len(salinity)):\n",
    "                prodnptile[v][prodnptile[v] == \"0\"] = \"nan\"\n",
    "                prodnptile[v][prodnptile[v] == \"1\"] = salinity[v]\n",
    "                prodnptile[v][prodnptile[v] == \"2\"] = temperature_processed[v] \n",
    "                prodnptile[v][prodnptile[v] == \"3\"] = phosphate_processed[v]\n",
    "                prodnptile[v][prodnptile[v] == \"4\"] = nitrate_processed[v]\n",
    "                prodnptile[v][prodnptile[v] == \"5\"] = silicate_processed[v]\n",
    "                prodnptile[v][prodnptile[v] == \"6\"] = oxygen_processed[v]\n",
    "                product_processed.append(prodnptile)\n",
    "                \n",
    "        listofprods = list(range(0, len(product)*n, n))\n",
    "        prodlist = []\n",
    "\n",
    "        names_values = list(need.values())\n",
    "        names_keys = list(need.keys())\n",
    "        unc_combo_dict = {}\n",
    "        dunc_combo_dict = {}\n",
    "\n",
    "        def get_uncertainty_array(name, uncertainties, default_size):\n",
    "            if name in uncertainties:\n",
    "                return np.array(uncertainties[name])\n",
    "            else:\n",
    "                return np.full(default_size, np.nan)\n",
    "                \n",
    "        for numb_combos, names_keyscombo in enumerate(names_values):\n",
    "\n",
    "            def define_unc_arrays(lengthofn, listorder, parnames, unames):\n",
    "                for numoptions in range(0, len(parnames)):\n",
    "                    if names_keyscombo[listorder] == parnames[numoptions]:\n",
    "                        udfvalues = np.array(Uncertainties[unames[numoptions]])\n",
    "                        dudfvalues = np.array(DUncertainties[unames[numoptions]])\n",
    "                    elif names_keyscombo[listorder] == \"nan\":\n",
    "                        udfvalues = np.empty((lengthofn))\n",
    "                        udfvalues[:] = np.nan\n",
    "                        dudfvalues = np.empty((lengthofn))\n",
    "                        dudfvalues[:] = np.nan\n",
    "                return udfvalues, dudfvalues\n",
    "            \n",
    "            for names_items in range(0, len(names_keyscombo)): # Fix this later\n",
    "                udfvalues1 = np.array(Uncertainties['sal_u'])\n",
    "                dudfvalues1 = np.array(DUncertainties['sal_u'])\n",
    "                udfvalues2, dudfvalues2 = define_unc_arrays(n, 1, [\"temperature\"], [\"temp_u\"])\n",
    "                udfvalues3, dudfvalues3 = define_unc_arrays(n, 2, [\"nitrate\", \"phosphate\"], [\"nitrate_u\", \"phosphate_u\"])\n",
    "                udfvalues4, dudfvalues4 = define_unc_arrays(n, 3, [\"oxygen\", \"nitrate\"], [\"oxygen_u\", \"nitrate_u\"])\n",
    "                udfvalues5, dudfvalues5 = define_unc_arrays(n, 4, [\"silicate\", \"nitrate\"], [\"silicate_u\", \"nitrate_u\"])\n",
    "               \n",
    "            # Convert to NumPy arrays for efficient comparison\n",
    "            udfvalues = np.array([udfvalues1, udfvalues2, udfvalues3, udfvalues4, udfvalues5])\n",
    "            dudfvalues = np.array([dudfvalues1, dudfvalues2, dudfvalues3, dudfvalues4, dudfvalues5])\n",
    "\n",
    "            # Update `udfvalues` based on `dudfvalues` using element-wise maximum\n",
    "            udfvalues = np.maximum(udfvalues, dudfvalues)\n",
    "\n",
    "            # Create DataFrames and set column names\n",
    "            new_unames = ['US', 'UT', 'UA', 'UB', 'UC']\n",
    "            uncertaintyvalues_df = pd.DataFrame(udfvalues.T, columns=new_unames)\n",
    "            duncertaintyvalues_df = pd.DataFrame(dudfvalues.T, columns=new_unames)\n",
    "\n",
    "            # Update dictionaries\n",
    "            unc_combo_dict[names_keys[numb_combos]] = uncertaintyvalues_df\n",
    "            dunc_combo_dict[names_keys[numb_combos]] = duncertaintyvalues_df\n",
    "\n",
    "        # Append the required products to `prodlist` and populate `precode`\n",
    "        prodlist = [product_processed[item] for item in listofprods]\n",
    "        precode = {name[i]: prodlist[i] for i in range(len(listofprods))}\n",
    "\n",
    "        S, T, A, B, Z, code = [], [], [], [], [], {}\n",
    "    \n",
    "        for value in precode.values():\n",
    "            S.append(value[:, 0])\n",
    "            T.append(value[:, 1])\n",
    "            A.append(value[:, 2])\n",
    "            B.append(value[:, 3])\n",
    "            Z.append(value[:, 4])\n",
    "        \n",
    "        codenames = list(precode.keys())\n",
    "        \n",
    "        common_columns = [\n",
    "            \"Order\", \"Dates\", \"Longitude\", \"Latitude\", \"Depth\", \n",
    "            \"Salinity_u\", \"Temperature_u\", \"Phosphate_u\", \n",
    "            \"Nitrate_u\", \"Silicate_u\", \"Oxygen_u\"\n",
    "        ]\n",
    "\n",
    "        # Iterate over codenames and create DataFrames\n",
    "        for n, cname in enumerate(codenames):\n",
    "            data = np.column_stack([S[n], T[n], A[n], B[n], Z[n]])\n",
    "            code[cname] = pd.DataFrame(data, columns=[\"S\", \"T\", \"A\", \"B\", \"C\"])\n",
    "            code[cname][common_columns] = InputAll[common_columns]\n",
    "   \n",
    "        # Loading the data       \n",
    "        def fetch_data (DesiredVariables):\n",
    "            for v in DesiredVariables:\n",
    "                P = Path\n",
    "                fname = f\"{P}/PyESPER/Mat_Polys/NN_files_{v}_Unc_Poly.mat\" # Change this according to your path\n",
    "                name = f\"NN_files_{v}_Unc_Poly\"\n",
    "                NNs = loadmat(fname)\n",
    "                Polys, UncGrid = NNs[\"Polys\"][0][0], NNs[\"UncGrid\"][0][0]\n",
    "        \n",
    "            NN_data = [Polys, UncGrid]\n",
    "            return NN_data\n",
    "\n",
    "        NN_data = fetch_data(DesiredVariables)\n",
    "\n",
    "        # Assessing the locations/regions of user-provided outputcoordinates\n",
    "        # Define Polygons\n",
    "        LNAPoly = np.array([[300, 0], [260, 20], [240, 67], [260, 40], [361, 40], [361, 0], [298, 0]])\n",
    "        LSAPoly = np.array([[298, 0], [292, -40.01], [361, -40.01], [361, 0], [298, 0]])\n",
    "        LNAPolyExtra = np.array([[-1, 50], [40, 50], [40, 0], [-1, 0], [-1, 50]])\n",
    "        LSAPolyExtra = np.array([[-1, 0], [20, 0], [20, -40], [-1, -40], [-1, 0]])\n",
    "        LNOPoly = np.array([[361, 40], [361, 91], [-1, 91], [-1, 50], [40, 50], [40, 40], [104, 40], [104, 67], [240, 67],\n",
    "                        [280, 40], [361, 40]])\n",
    "        xtra = np.array([[0.5, -39.9], [.99, -39.9], [0.99, -40.001], [0.5, -40.001]])\n",
    "\n",
    "        polygons = [LNAPoly, LSAPoly, LNAPolyExtra, LSAPolyExtra, LNOPoly, xtra]\n",
    "\n",
    "        # Create Paths\n",
    "        paths = [mpltPath.Path(poly) for poly in polygons]\n",
    "\n",
    "        # Extract coordinates\n",
    "        latitude, depth = np.array(C[\"latitude\"]), np.array(C[\"depth\"])\n",
    "    \n",
    "        # Check if coordinates are within each polygon\n",
    "        conditions = [path.contains_points(np.column_stack((longitude, latitude))) for path in paths]\n",
    "\n",
    "        # Combine conditions\n",
    "        AAIndsM = np.logical_or.reduce(conditions)\n",
    "\n",
    "        # Adding Bering Sea, S. Atl., and S. African Polygons separately \n",
    "        Bering = np.array([[173, 70], [210, 70], [210, 62.5], [173, 62.5], [173, 70]])\n",
    "        beringpath = mpltPath.Path(Bering)\n",
    "        beringconditions = beringpath.contains_points(np.column_stack((longitude, latitude)))\n",
    "        SAtlInds, SoAfrInds = [], []\n",
    "        for i, z in zip(longitude, latitude):\n",
    "            # Check if the conditions are met for Southern Atlantic\n",
    "            if (-34 > z > -44):  # Check latitude first to reduce unnecessary checks\n",
    "                if i > 290 or i < 20:\n",
    "                    SAtlInds.append('True')\n",
    "                else:\n",
    "                    SAtlInds.append('False')\n",
    "        \n",
    "                # Check if the condition is met for Southern Africa\n",
    "                if 19 < i < 27:\n",
    "                    SoAfrInds.append('True')\n",
    "                else:\n",
    "                    SoAfrInds.append('False')\n",
    "            else:\n",
    "                SAtlInds.append('False')\n",
    "                SoAfrInds.append('False')\n",
    "      \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame({'AAInds': AAIndsM, 'BeringInds': beringconditions, 'SAtlInds': SAtlInds, \\\n",
    "                           'SoAfrInds': SoAfrInds, 'Lat': latitude, 'Lon': longitude, 'Depth': depth})\n",
    "\n",
    "        # Running the neural networks\n",
    "        combos = list(code.keys())\n",
    "        combovalues = list(code.values())\n",
    "        EstAtl, EstOther = {}, {}\n",
    "        P, Sd, Td, Ad, Bd, Cd = {}, {}, {}, {}, {}, {} \n",
    "\n",
    "        for name, value in zip(combos, combovalues):\n",
    "            cosd = np.cos(np.deg2rad(value[\"Longitude\"] - 20)).tolist()\n",
    "            sind = np.sin(np.deg2rad(value[\"Longitude\"] - 20)).tolist()\n",
    "            lat, depth = value[\"Latitude\"].tolist(), value[\"Depth\"].tolist()\n",
    "            # Convert columns to lists of floats\n",
    "            Sd[name] = value[\"S\"].astype(float).tolist()\n",
    "            Td[name] = value[\"T\"].astype(float).tolist()\n",
    "            Ad[name] = value[\"A\"].astype(float).tolist()\n",
    "            Bd[name] = value[\"B\"].astype(float).tolist()\n",
    "            Cd[name] = value[\"C\"].astype(float).tolist()\n",
    "\n",
    "        # Define a mapping from equations to the list of variables\n",
    "        equation_map = {\n",
    "            1: [\"Sd\", \"Td\", \"Ad\", \"Bd\", \"Cd\"],\n",
    "            2: [\"Sd\", \"Td\", \"Ad\", \"Cd\"],\n",
    "            3: [\"Sd\", \"Td\", \"Bd\", \"Cd\"],\n",
    "            4: [\"Sd\", \"Td\", \"Cd\"],\n",
    "            5: [\"Sd\", \"Td\", \"Ad\", \"Bd\"],\n",
    "            6: [\"Sd\", \"Td\", \"Ad\"],\n",
    "            7: [\"Sd\", \"Td\", \"Bd\"],\n",
    "            8: [\"Sd\", \"Td\"],\n",
    "            9: [\"Sd\", \"Ad\", \"Bd\", \"Cd\"],\n",
    "            10: [\"Sd\", \"Ad\", \"Cd\"],\n",
    "            11: [\"Sd\", \"Bd\", \"Cd\"],\n",
    "            12: [\"Sd\", \"Cd\"],\n",
    "            13: [\"Sd\", \"Ad\", \"Bd\"],\n",
    "            14: [\"Sd\", \"Ad\"],\n",
    "            15: [\"Sd\", \"Bd\"],\n",
    "            16: [\"Sd\"]\n",
    "        }\n",
    "\n",
    "        # Create the correct vector for each equation case\n",
    "        for v in DesiredVariables:\n",
    "            for e in Equations:\n",
    "                name = v + str(e)\n",
    "                # Get the corresponding variables for the equation\n",
    "                variables = [locals()[var][name] for var in equation_map[e]]\n",
    "                P[name] = [[[cosd, sind, lat, depth] + variables]]\n",
    "                netname = [\"1\", \"2\", \"3\", \"4\"]\n",
    "                netstimateAtl, netstimateOther = [], []\n",
    "                for n in range(1, 5):\n",
    "                    fOName = f\"ESPER_{v}_{e}_Other_{n}\"\n",
    "                    fAName = f\"ESPER_{v}_{e}_Atl_{n}\"\n",
    "                    moda = importlib.import_module(fAName)\n",
    "                    modo = importlib.import_module(fOName)\n",
    "                    from importlib import reload\n",
    "                    reload(moda)\n",
    "                    reload(modo)\n",
    "\n",
    "                    netstimateAtl.append(moda.PyESPER_NN(P[name]))\n",
    "                    netstimateOther.append(modo.PyESPER_NN(P[name]))\n",
    "            \n",
    "                # Process estimates for Atlantic and Other regions\n",
    "                EstAtlL = [[netstimateAtl[na][0][eatl] for na in range(4)] for eatl in range(len(netstimateAtl[0][0]))]\n",
    "                EstOtherL = [[netstimateOther[no][0][eoth] for no in range(4)] for eoth in range(len(netstimateOther[0][0]))]\n",
    "\n",
    "                # Store the results\n",
    "                EstAtl[name] = EstAtlL\n",
    "                EstOther[name] = EstOtherL\n",
    "    \n",
    "        def process_estimates(estimates):\n",
    "            keys = list(estimates.keys())\n",
    "            values = list(estimates.values())\n",
    "            result = {}\n",
    "            for i, key in enumerate(keys):\n",
    "                result[key] = [mean(values[i][v]) for v in range(len(values[0]))]\n",
    "            return result\n",
    "\n",
    "        Esta = process_estimates(EstAtl)\n",
    "        Esto = process_estimates(EstOther)\n",
    "\n",
    "        # Processing regionally in the Atlantic and Bering\n",
    "        EstA, EstB, EB2, ESat, ESat2, ESaf, Estimate  = {}, {}, {}, {}, {}, {}, {}\n",
    "\n",
    "        for i in code:\n",
    "            code[i][\"AAInds\"] = df[\"AAInds\"]\n",
    "            code[i][\"BeringInds\"] = df[\"BeringInds\"]\n",
    "            code[i][\"SAtlInds\"] = df[\"SAtlInds\"]\n",
    "            code[i][\"SoAfrInds\"] = df[\"SoAfrInds\"]\n",
    "        \n",
    "        for codename, codedata in code.items():\n",
    "            Estatl, Estb, eb2, Estsat, esat2, esafr, esaf2 = [], [], [], [], [], [], []\n",
    "            aainds, beringinds, satlinds, latitude, safrinds = (\n",
    "                codedata[key] for key in [\"AAInds\", \"BeringInds\", \"SAtlInds\", \"Latitude\", \"SoAfrInds\"]\n",
    "            )\n",
    "\n",
    "            Estatl = [Esta[codename][i] if aa_ind else Esto[codename][i] for i, aa_ind in enumerate(aainds)]\n",
    "\n",
    "            for l in range(0, len(Estatl)):\n",
    "                repeated_values = (latitude[l]-62.5)/7.5\n",
    "                B = np.tile(repeated_values, (1, len(Equations)))\n",
    "                C = Esta[codename][l]\n",
    "                B1 = C * B\n",
    "                repeated_values2 = (70-latitude[l])/7.5\n",
    "                D = np.tile(repeated_values2, (1, len(Equations)))\n",
    "                E = Esto[codename][l]\n",
    "                B2 = E * D\n",
    "                Estb.append(B1[0][0] + B2[0][0])\n",
    "\n",
    "            eb2 = [Estb[j] if b_ind else Estatl[j] for j, b_ind in enumerate(beringinds)]\n",
    "\n",
    "            for n in range(0, len(satlinds)): \n",
    "                repeated_values = (latitude[n]+44)/10\n",
    "                F1 = Esta[codename][n]\n",
    "                F = np.tile(repeated_values, (1, len(Equations)))\n",
    "                G1 = F1 * F\n",
    "                repeated_values2 = (-34-latitude[n])/10\n",
    "                H1 = Esto[codename][n]\n",
    "                H = np.tile(repeated_values2, (1, len(Equations)))\n",
    "                G2 = H1 * H\n",
    "                Estsat.append(G1[0][0] + G2[0][0])\n",
    "    \n",
    "            EstA[codename], EstB[codename], EB2[codename], ESat[codename] = Estatl, Estb, eb2, Estsat\n",
    "\n",
    "        # Regional processing for S. Atlantic\n",
    "            ESat2[codename] = [\n",
    "                ESat[codename][i] if satlinds[i] == \"True\" else EB2[codename][i]\n",
    "                for i in range(len(satlinds))\n",
    "            ]\n",
    "            \n",
    "        # Regional processing for S. Africa\n",
    "            for s in range(0, len(safrinds)):\n",
    "                repeated_values = (27-longitude[s])/8\n",
    "                F1 = ESat2[codename][s]\n",
    "                F = np.tile(repeated_values, (1, len(Equations)))\n",
    "                G1 = F1*F\n",
    "                repeated_values2 = (longitude[s]-19)/8\n",
    "                H1 = Esto[codename][s]\n",
    "                H = np.tile(repeated_values2, (1, len(Equations)))\n",
    "                G2 = H1 * H\n",
    "                esafr.append(G1[0][0] + G2[0][0])\n",
    "\n",
    "            ESaf[codename] = esafr\n",
    "\n",
    "            Estimate[codename] = [\n",
    "                ESaf[codename][i] if safrinds[i] == \"True\" else ESat2[codename][i]\n",
    "                for i in range(len(safrinds))\n",
    "            ]\n",
    "\n",
    "        # Bookkeeping blanks back to NaN as needed\n",
    "        Estimate = {k: ('NaN' if v == '' else v) for k, v in Estimate.items()}\n",
    "        no_equations = len(Equations)\n",
    "\n",
    "        # Estimating EMLR\n",
    "        def EMLR_Estimate(DesiredVariables, OutputCoordinates={}, PredictorMeasurements={}, **kwargs):\n",
    "           \n",
    "            EMLR = []\n",
    "            for dv in DesiredVariables:\n",
    "                NN_data = fetch_data([dv])\n",
    "\n",
    "                data_arrays = [\n",
    "                    np.nan_to_num(np.array([\n",
    "                        NN_data[1][i][c][b][a]\n",
    "                        for a in range(16)\n",
    "                        for b in range(11)\n",
    "                        for c in range(8)\n",
    "                    ]))\n",
    "                    for i in range(4)\n",
    "                ]\n",
    "        \n",
    "                # Create DataFrame with meaningful column names\n",
    "                UGridArray = pd.DataFrame({\n",
    "                    'UDepth': data_arrays[0],\n",
    "                    'USal': data_arrays[1],\n",
    "                    'Eqn': data_arrays[2],\n",
    "                    'RMSE': data_arrays[3],\n",
    "                })\n",
    "        \n",
    "                UGridPoints = (UGridArray['UDepth'], UGridArray['USal'], UGridArray['Eqn'])\n",
    "                UGridValues = UGridArray['RMSE']\n",
    "        \n",
    "                # Perform estimation for each equation\n",
    "                EM = [\n",
    "                    griddata(\n",
    "                        UGridPoints, UGridValues,\n",
    "                        (OutputCoordinates['depth'], PredictorMeasurements['salinity'], [Equations[eq]] * len(PredictorMeasurements['salinity'])),\n",
    "                        method='linear'\n",
    "                    )\n",
    "                    for eq in range(no_equations)\n",
    "                ]\n",
    "        \n",
    "                EMLR.append(EM)\n",
    "    \n",
    "            return EMLR\n",
    "\n",
    "        EMLR = EMLR_Estimate(DesiredVariables, OutputCoordinates, PredictorMeasurements)\n",
    "        \n",
    "        return PredictorMeasurements, Estimate, Uncertainties, DUncertainties, EMLR # PredictorMeasurements: Dictionary, Estimate: Dictionary, \n",
    "    \n",
    "    # Uncertainties: pd DataFrame, DUncertainties: pd DataFrame, EMLR:list\n",
    "    PD_final, DPD_final, Unc_final, DUnc_final = [], [], [], []\n",
    "    PMs_pre, Est_pre, U_pre, DU_pre, EMLR = preprocess_applynets(\n",
    "        DesiredVariables, \n",
    "        Equations, \n",
    "        EstDates,\n",
    "        VerboseTF,\n",
    "        C, \n",
    "        PredictorMeasurements,\n",
    "        Uncertainties_pre,\n",
    "        DUncertainties_pre\n",
    "    )\n",
    "\n",
    "    for d, var in enumerate(DesiredVariables):\n",
    "        Pertdv, DPertdv, Unc, DUnc = [], [], [], []\n",
    "        var = [var]  # Wrap single variable in a list\n",
    "        keys = [\"sal_u\", \"temp_u\", \"phosphate_u\", \"nitrate_u\", \"silicate_u\", \"oxygen_u\"]\n",
    "\n",
    "        PredictorMeasurements2, Est, Uncertainties, DUncertainties, emlr = preprocess_applynets(\n",
    "            var, \n",
    "            Equations, \n",
    "            EstDates, \n",
    "            ['False'], \n",
    "            OutputCoordinates, \n",
    "            PredictorMeasurements, \n",
    "            Uncertainties_pre, \n",
    "            DUncertainties_pre\n",
    "        )\n",
    "        \n",
    "        names = list(PredictorMeasurements2.keys())\n",
    "        PMs = list(PredictorMeasurements2.values())\n",
    "\n",
    "        # Replace \"nan\" with 0 in PMs using list comprehensions\n",
    "        PMs_nonan = [[0 if val == \"nan\" else val for val in pm] for pm in PMs]\n",
    "\n",
    "        # Transpose PMs_nonan\n",
    "        PMs = np.transpose(PMs_nonan)\n",
    "\n",
    "        PMs3, DMs3 = {}, {}\n",
    "\n",
    "        for pred in range(len(PredictorMeasurements2)):\n",
    "            num_coords = len(OutputCoordinates['longitude'])\n",
    "            num_preds = len(PredictorMeasurements2)\n",
    "\n",
    "            # Initialize perturbation arrays\n",
    "            Pert = np.zeros((num_coords, num_preds))\n",
    "            DefaultPert = np.zeros((num_coords, num_preds))\n",
    "\n",
    "            # Populate perturbation arrays\n",
    "            Pert[:, pred] = Uncertainties[keys[pred]]\n",
    "            DefaultPert[:, pred] = DUncertainties[keys[pred]]\n",
    "\n",
    "            # Apply perturbations\n",
    "            PMs2 = PMs + Pert\n",
    "            DMs2 = PMs + DefaultPert\n",
    "\n",
    "           # Update PMs3 and DMs3 dictionaries\n",
    "            for col, name in enumerate(names):\n",
    "                PMs3[name] = PMs2[:, col].tolist()\n",
    "                DMs3[name] = DMs2[:, col].tolist()\n",
    "\n",
    "            # Run preprocess_applynets for perturbed and default data\n",
    "            VTF = False\n",
    "            _, PertEst, _, _, _ = preprocess_applynets(\n",
    "                var, Equations, EstDates, VTF, OutputCoordinates, PMs3, Uncertainties_pre, DUncertainties_pre\n",
    "            )\n",
    "            _, DefaultPertEst, _, _, _ = preprocess_applynets(\n",
    "                var, Equations, EstDates, VTF, OutputCoordinates, DMs3, Uncertainties_pre, DUncertainties_pre\n",
    "            )\n",
    "\n",
    "            # Extract estimates and perturbation results\n",
    "            combo, estimates = list(Est.keys()), list(Est.values())\n",
    "            pertests, defaultpertests = list(PertEst.values()), list(DefaultPertEst.values())\n",
    "\n",
    "            # Initialize result lists\n",
    "            PertDiff, DefaultPertDiff, Unc_sub2, DUnc_sub2 = [], [], [], []\n",
    "        \n",
    "            for c in range(len(Equations)):\n",
    "                # Compute differences and squared differences using list comprehensions\n",
    "                PD = [estimates[c][e] - pertests[c][e] for e in range(len(estimates[c]))]\n",
    "                DPD = [estimates[c][e] - defaultpertests[c][e] for e in range(len(estimates[c]))]\n",
    "                Unc_sub1 = [(estimates[c][e] - pertests[c][e])**2 for e in range(len(estimates[c]))]\n",
    "                DUnc_sub1 = [(estimates[c][e] - defaultpertests[c][e])**2 for e in range(len(estimates[c]))]\n",
    "\n",
    "                # Append results to their respective lists\n",
    "                PertDiff.append(PD)\n",
    "                DefaultPertDiff.append(DPD)\n",
    "                Unc_sub2.append(Unc_sub1)\n",
    "                DUnc_sub2.append(DUnc_sub1)\n",
    "            Pertdv.append(PertDiff)\n",
    "            DPertdv.append(DefaultPertDiff)\n",
    "            Unc.append(Unc_sub2)\n",
    "            DUnc.append(DUnc_sub2)\n",
    "        PD_final.append(Pertdv)\n",
    "        DPD_final.append(DPertdv)\n",
    "        Unc_final.append(Unc)\n",
    "        DUnc_final.append(DUnc) # CHECK THIS WHOle shebang next\n",
    "\n",
    "    est = list(Est_pre.values())\n",
    "    Uncertainties = []\n",
    "    propu = []\n",
    "    for dv in range(0, len(DesiredVariables)):\n",
    "        dvu = []\n",
    "        for eq in range(0, len(Equations)):\n",
    "            sumu = []\n",
    "            for n in range(0, len(est[0])):\n",
    "                u, du = [], []\n",
    "                for pre in range(0, len(PredictorMeasurements)):\n",
    "                    u.append(Unc_final[dv][pre][eq][n])\n",
    "                    du.append(DUnc_final[dv][pre][eq][n])\n",
    "                eu = EMLR[dv][eq][n]\n",
    "                sumu.append((sum(u) - sum(du) + eu**2)**(1/2))\n",
    "            dvu.append(sumu)\n",
    "        propu.append(dvu)\n",
    "    Uncertainties.append(propu)\n",
    "    YouHaveBeenWarnedCanth = False\n",
    "\n",
    "\n",
    "    def SimpleCantEstimateLR(EstDates, longitude, latitude, depth):\n",
    "        # Load interpolation points and values\n",
    "        CantIntPoints = pd.read_csv('SimpleCantEstimateLR_full.csv')\n",
    "        pointsi = (\n",
    "            CantIntPoints['Int_long'] * 0.25,\n",
    "            CantIntPoints['Int_lat'],\n",
    "            CantIntPoints['Int_depth'] * 0.025,\n",
    "        )\n",
    "        values = CantIntPoints['values']\n",
    "\n",
    "        # Scale input coordinates\n",
    "        pointso = (\n",
    "            np.array(longitude) * 0.25,\n",
    "            np.array(latitude),\n",
    "            np.array(depth) * 0.025,\n",
    "        )\n",
    "\n",
    "        # Interpolate and compute Cant2002\n",
    "        Cant2002 = griddata(pointsi, values, pointso, method='linear')\n",
    "\n",
    "        # Adjust for estimation dates\n",
    "        CantMeas = [\n",
    "            c * math.exp(0.018989 * (date - 2002)) for c, date in zip(Cant2002, EstDates)\n",
    "        ]\n",
    "\n",
    "        return CantMeas, Cant2002\n",
    "\n",
    "    Cant_adjusted = {}\n",
    "    combos2 = list(Est_pre.keys())\n",
    "    values2 = list(Est_pre.values())\n",
    "\n",
    "    if \"EstDates\" in kwargs and (\"DIC\" in DesiredVariables or \"pH\" in DesiredVariables):      \n",
    "        if not YouHaveBeenWarnedCanth:\n",
    "            if VerboseTF:\n",
    "                print(\"Estimating anthropogenic carbon for PyESPER_NN.\")\n",
    "            longitude = np.mod(OutputCoordinates[\"longitude\"], 360)\n",
    "            latitude = np.array(OutputCoordinates[\"latitude\"])\n",
    "            depth = np.array(OutputCoordinates[\"depth\"])\n",
    "            Cant, Cant2002 = SimpleCantEstimateLR(EstDates, longitude, latitude, depth)\n",
    "            YouHaveBeenWarnedCanth = True\n",
    "\n",
    "        for combo, a in zip(combos2, values2):\n",
    "            dic = []\n",
    "            if combo.startswith(\"DIC\"):\n",
    "                for vala, Canta, Cant2002a in zip(a, Cant, Cant2002):\n",
    "                    if math.isnan(vala): \n",
    "                        dic.append(\"nan\")\n",
    "                    else:\n",
    "                        dic.append(vala + Canta - Cant2002a)\n",
    "            else:\n",
    "                dic = list(a)\n",
    "            Cant_adjusted[combo] = dic\n",
    "                 \n",
    "        if \"pH\" in DesiredVariables:\n",
    "            warning = []\n",
    "            for combo, values in zip(combos2, values2):\n",
    "                if combo.startswith(\"pH\"):\n",
    "                    salinity = PredictorMeasurements[\"salinity\"]\n",
    "                    PM_pH = {'salinity': salinity}\n",
    "                    eq = [16]\n",
    "                    alkpm, alkest, _, _, _ = preprocess_applynets(\n",
    "                        [\"TA\"], eq, EstDates, ['False'], C, PM_pH, Uncertainties_pre, DUncertainties_pre\n",
    "                    )\n",
    "                    EstAlk = np.array(alkest[\"TA16\"])\n",
    "                    EstSi = EstP = [0] * len(EstAlk)\n",
    "                    Pressure = sw.pres(OutputCoordinates[\"depth\"], OutputCoordinates[\"latitude\"])\n",
    "                    Est = np.array(values)\n",
    "\n",
    "                    # CO2SYS calculations\n",
    "                    Out = pyco2.sys(\n",
    "                        par1=EstAlk, par2=Est, par1_type=1, par2_type=3, salinity=salinity,\n",
    "                        temperature=PredictorMeasurements[\"temperature\"], temperature_out=PredictorMeasurements[\"temperature\"],\n",
    "                        pressure=Pressure, pressure_out=Pressure, total_silicate=EstSi, total_phosphate=EstP, opt_total_borate=2\n",
    "                    )\n",
    "                    DICadj = Out[\"dic\"] + Cant - Cant2002\n",
    "                    OutAdj = pyco2.sys(\n",
    "                        par1=EstAlk, par2=DICadj, par1_type=1, par2_type=2, salinity=salinity,\n",
    "                        temperature=PredictorMeasurements[\"temperature\"], temperature_out=PredictorMeasurements[\"temperature\"],\n",
    "                        pressure=Pressure, pressure_out=Pressure, total_silicate=EstSi, total_phosphate=EstP, opt_total_borate=2\n",
    "                    )\n",
    "                    pHadj = OutAdj[\"pH\"]\n",
    "\n",
    "                    # Check for convergence warnings\n",
    "                    if any(np.isnan(pHadj)):\n",
    "                        warning_message = (\n",
    "                            \"Warning: CO2SYS took >20 iterations to converge. The corresponding estimate(s) will be NaN. \"\n",
    "                            \"This typically happens when ESPER_NN is poorly suited for estimating water with the given properties \"\n",
    "                            \"(e.g., very high or low salinity or estimates in marginal seas).\"\n",
    "                        )\n",
    "                        warning.append(warning_message)\n",
    "                else:\n",
    "                    pHadj = np.array(values)\n",
    "\n",
    "                Cant_adjusted[combo] = pHadj.tolist()\n",
    "\n",
    "            # Print warnings if any\n",
    "            if warning:\n",
    "                print(warning[0])\n",
    "\n",
    "    elif \"EstDates\" not in kwargs and (\"DIC\" or \"pH\" in DesiredVariables) and VerboseTF == True and YouHaveBeenWarnedCanth == False:\n",
    "        print(\"Warning: DIC or pH is a requested output but the user did not provide dates for the desired estimates.  The estimates will be specific to 2002.0 unless the optional EstDates input is provided (recommended).\")\n",
    "        YouHaveBeenWarnedCanth = True\n",
    "\n",
    "    if kwargs.get(\"pHCalcTF\") == True and \"pH\" in DesiredVariables:\n",
    "        if VerboseTF == True:\n",
    "            print(\"Recalculating the pH to be appropriate for pH values calculated from TA and DIC.\")\n",
    "        for combo, pH_values in zip(combos2, values2):\n",
    "            if combo.startswith(\"pH\"):\n",
    "                pH_adjcalc_Est = [(pH + 0.3168) / 1.0404 for pH in pH_values]\n",
    "                Cant_adjusted[combo] = pH_adjcalc_Est\n",
    "\n",
    "    # Prepare data for processing\n",
    "    combos3 = Cant_adjusted.keys()\n",
    "    values3 = Cant_adjusted.values()\n",
    "    Us = Uncertainties[0]\n",
    "    Us2 = [u2 for u in Us for u2 in u]\n",
    "\n",
    "    # Convert combos and values to lists for iteration\n",
    "    k2, v2 = list(combos2), list(values2)\n",
    "    k3, v3 = list(combos3), list(values3)\n",
    "\n",
    "    # Initialize estimates and uncertainties dictionaries\n",
    "    Estimates, Uncerts = {}, {}\n",
    "\n",
    "    for key2, value2 in zip(k2, v2):\n",
    "        # Adjust values in v2 based on matches in k3\n",
    "        adjusted_array = np.array(value2)\n",
    "        for key3, value3 in zip(k3, v3):\n",
    "            adjusted_array[key2 == key3] = value3\n",
    "\n",
    "        # Store adjusted values and uncertainties\n",
    "        Estimates[key2] = adjusted_array\n",
    "        Uncerts[key2] = Us2[k2.index(key2)]\n",
    "\n",
    "    # Convert results to DataFrame\n",
    "    Estimates = pd.DataFrame(Estimates)\n",
    "    Uncertainties = pd.DataFrame(Uncerts)\n",
    "\n",
    "    toc = time.perf_counter()\n",
    "    print(f\"PyESPER_NN took {toc - tic:0.4f} seconds, or {(toc-tic)/60:0.4f} minutes to run\")    \n",
    "\n",
    "    return Estimates, Uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4a9e76e-cc4c-4c2b-8fb5-f7d1a3388dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PyESPER_Mixed(DesiredVariables, Path, OutputCoordinates={}, PredictorMeasurements={}, **kwargs):\n",
    "    \n",
    "    \"\"\"\n",
    "    Python interpretation of ESPER_Mixedv1.1\n",
    "\n",
    "    Empirical Seawater Property Estimation Routines: Estimates seawater properties and estimate uncertainty from combinations of other parameter\n",
    "    measurements.  PYESPER_Mixed refers specifically to code that averages estunated from PyESPER_NN and PyESPER_LIR. See either subfunction for\n",
    "    comments. The input arguments are the same for this function and for both subfunctions.\n",
    "    \n",
    "    *************************************************************************\n",
    "    Please send questions or related requests about PyESPER to lmdias@uw.edu.\n",
    "    ************************************************************************* \n",
    "    \"\"\"\n",
    "    \n",
    "    tic = time.perf_counter()\n",
    "\n",
    "    # Fetch estimates and uncertainties from PyESPER_LIR and PyESPER_NN\n",
    "    EstimatesLIR, UncertaintiesLIR, _ = PyESPER_LIR(DesiredVariables, Path, OutputCoordinates, PredictorMeasurements, **kwargs)\n",
    "    EstimatesNN, UncertaintiesNN = PyESPER_NN(DesiredVariables, Path, OutputCoordinates, PredictorMeasurements, **kwargs)\n",
    "\n",
    "    Estimates, Uncertainties = {}, {}\n",
    "    for est_type in EstimatesLIR.keys():\n",
    "        estimates_lir = np.array(EstimatesLIR[est_type])\n",
    "        estimates_nn = np.array(EstimatesNN[est_type])\n",
    "        uncertainties_lir = np.array(UncertaintiesLIR[est_type])\n",
    "        uncertainties_nn = np.array(UncertaintiesNN[est_type])\n",
    "\n",
    "        Estimates[est_type] = np.mean([estimates_lir, estimates_nn], axis=0).tolist()\n",
    "        Uncertainties[est_type] = np.min([uncertainties_lir, uncertainties_nn], axis=0).tolist()\n",
    "\n",
    "    toc = time.perf_counter()\n",
    "    print(f\"PyESPER_Mixed took {toc - tic:0.4f} seconds, or {(toc-tic)/60:0.4f} minutes to run\")    \n",
    "\n",
    "    return pd.DataFrame(Estimates), pd.DataFrame(Uncertainties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccce3e1e-4cd9-48d6-8993-4eddf7d744a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating anthropogenic carbon for PyESPER_NN.\n",
      "PyESPER_NN took 7.1440 seconds, or 0.1191 minutes to run\n",
      "Estimating anthropogenic carbon for PyESPER_NN.\n",
      "pH is detected\n",
      "Warning: CO2SYS took >20 iterations to converge. The corresponding estimate(s) will be NaN. This typically happens when ESPER_LIR is poorly suited for estimating water with the given properties (e.g., very high or low salinity or estimates in marginal seas).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/larissadias/Documents/Python/PyESPER/Final_code/ESPER_TA_1_Atl_2.py:37: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * n)) - 1\n",
      "/Users/larissadias/Documents/Python/PyESPER/Final_code/ESPER_TA_1_Atl_2.py:37: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * n)) - 1\n",
      "/Users/larissadias/Documents/Python/PyESPER/Final_code/ESPER_TA_1_Atl_2.py:37: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * n)) - 1\n",
      "/Users/larissadias/Documents/Python/PyESPER/Final_code/ESPER_TA_1_Atl_2.py:37: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * n)) - 1\n",
      "/Users/larissadias/Documents/Python/PyESPER/Final_code/ESPER_TA_1_Atl_2.py:37: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * n)) - 1\n",
      "/Users/larissadias/Documents/Python/PyESPER/Final_code/ESPER_TA_1_Atl_2.py:37: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * n)) - 1\n",
      "/Users/larissadias/Documents/Python/PyESPER/Final_code/ESPER_TA_1_Atl_2.py:37: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * n)) - 1\n",
      "/Users/larissadias/Documents/Python/PyESPER/Final_code/ESPER_TA_1_Atl_2.py:37: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * n)) - 1\n",
      "/Users/larissadias/Documents/Python/PyESPER/Final_code/ESPER_TA_1_Atl_2.py:37: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * n)) - 1\n",
      "/Users/larissadias/Documents/Python/PyESPER/Final_code/ESPER_TA_1_Atl_2.py:37: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * n)) - 1\n",
      "/Users/larissadias/Documents/Python/PyESPER/Final_code/ESPER_TA_1_Atl_2.py:37: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * n)) - 1\n",
      "/Users/larissadias/Documents/Python/PyESPER/Final_code/ESPER_TA_1_Atl_2.py:37: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * n)) - 1\n",
      "/Users/larissadias/Documents/Python/PyESPER/Final_code/ESPER_TA_1_Atl_2.py:37: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * n)) - 1\n",
      "/Users/larissadias/Documents/Python/PyESPER/Final_code/ESPER_TA_1_Atl_2.py:37: RuntimeWarning: overflow encountered in exp\n",
      "  return 2 / (1 + np.exp(-2 * n)) - 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyESPER_NN took 4.2964 seconds, or 0.0716 minutes to run\n",
      "           DIC1\n",
      "90  2071.800659\n",
      "91  2119.485197\n",
      "92  2132.322540\n",
      "93  2136.700420\n",
      "94  2143.980107\n",
      "95  2146.274469\n",
      "96  2148.855030\n",
      "97  2149.882212\n",
      "98  2150.823218\n",
      "99  2151.664373          pH1\n",
      "10  0.007381\n",
      "11  0.007372\n",
      "12  0.006940\n",
      "13  0.006517\n",
      "14  0.006315\n",
      "15  0.006037\n",
      "16  0.005959\n",
      "17  0.006968\n",
      "18  0.024442\n",
      "19  0.017099    phosphate1  phosphate2          TA1          TA2\n",
      "0    0.848410    0.849892  2304.737916  2303.620479\n",
      "1    0.863526    0.863886  2300.965597  2300.508572\n",
      "2    0.868582    0.867914  2299.578411  2298.667004\n",
      "3    0.884773    0.884751  2298.922926  2298.277296\n",
      "4    0.890833    0.893829  2297.166634  2297.016552\n",
      "5    0.914835    0.915058  2298.636539  2298.216202\n",
      "6    0.935708    0.935798  2299.119335  2298.754956\n",
      "7    0.952455    0.953147  2299.235524  2299.096184\n",
      "8    0.965701    0.966641  2298.754643  2298.708025\n",
      "9    0.973029    0.974004  2298.907562  2298.811426\n"
     ]
    }
   ],
   "source": [
    "# EXAMPLE\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "\n",
    "data = loadmat(\"GLODAPv2.2022_Merged_Master_File.mat\") \n",
    "\n",
    "latitude_array = np.squeeze(data['G2latitude'][500:1000])\n",
    "latitude = latitude_array.tolist()\n",
    "longitude_array = np.squeeze(data['G2longitude'][500:1000])\n",
    "longitude = longitude_array.tolist()\n",
    "depth_array = np.squeeze(data['G2depth'][500:1000])\n",
    "depth = depth_array.tolist()\n",
    "salinity_array = np.squeeze(data['G2salinity'][500:1000])\n",
    "salinity = salinity_array.tolist()\n",
    "temperature_array = np.squeeze(data['G2temperature'][500:1000])\n",
    "temperature = temperature_array.tolist()\n",
    "phosphate_array = np.squeeze(data['G2phosphate'][500:1000])\n",
    "phosphate = phosphate_array.tolist()\n",
    "nitrate_array = np.squeeze(data['G2nitrate'][500:1000])\n",
    "nitrate = nitrate_array.tolist()\n",
    "silicate_array = np.squeeze(data['G2silicate'][500:1000])\n",
    "silicate = silicate_array.tolist()\n",
    "oxygen_array = np.squeeze(data['G2oxygen'][500:1000])\n",
    "oxygen = oxygen_array.tolist()\n",
    "\n",
    "OutputCoordinates = {}\n",
    "PredictorMeasurements = {}\n",
    "\n",
    "OutputCoordinates.update({\"longitude\": longitude, \n",
    "                          \"latitude\": latitude, \n",
    "                          \"depth\": depth})\n",
    "\n",
    "PredictorMeasurements.update({\"salinity\": salinity, \n",
    "                              \"temperature\": temperature, \n",
    "                              \"phosphate\": phosphate, \n",
    "                              \"nitrate\": nitrate, \n",
    "                              \"silicate\": silicate, \n",
    "                              \"oxygen\": oxygen\n",
    "                             })\n",
    "\n",
    "MeasUncerts = {'sal_u': [0.001], 'temp_u': [0.3], 'phosphate_u': [0.14], 'nitrate_u':[0.5], 'silicate_u': [0.03], 'oxygen_u': [0.025]}\n",
    "\n",
    "EstDates_array = np.squeeze(data['G2year'][500:1000])\n",
    "EstDates = EstDates_array.tolist()\n",
    "\n",
    "Path = '/Users/larissadias/Documents/Python'\n",
    "             \n",
    "EstimatesNN, UncertaintiesNN = PyESPER_NN(['DIC'], Path, OutputCoordinates, PredictorMeasurements, EstDates=EstDates, Equations=[1])\n",
    "EstimatesLIR, UncertaintiesLIR, CoefficientsLIR = PyESPER_LIR(['pH'], Path, OutputCoordinates, PredictorMeasurements, EstDates=EstDates, Equations=[1])\n",
    "EstimatesMixed, UncertaintiesMixed = PyESPER_Mixed(['phosphate', 'TA'], Path, OutputCoordinates, PredictorMeasurements, VerboseTF=True, EstDates=EstDates, MeasUncerts=MeasUncerts, Equations=[1, 2])\n",
    "print(EstimatesNN[90:100], UncertaintiesLIR[10:20], EstimatesMixed[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0fd01ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want fewer command line updates (less text), run PyESPER through the following code (same as VerboseTF = False from the MATLAB\n",
    "    # version). Otherwise skip to PyESPER function.\n",
    "\n",
    "from contextlib import contextmanager\n",
    "import sys, os\n",
    "\n",
    "@contextmanager\n",
    "def suppress_stdout():\n",
    "    \"\"\"\n",
    "    Function to suppress command-line updates.\n",
    "    \"\"\"\n",
    "    with open(os.devnull, \"w\") as devnull:\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = devnull\n",
    "        try:  \n",
    "            yield\n",
    "        finally:\n",
    "            sys.stdout = old_stdout\n",
    "\n",
    "            \n",
    "            \n",
    "def verbose_tf(DesiredVariables, OutputCoordinates, PredictorMeasurements, **kwargs):\n",
    "    \"\"\"\n",
    "    Reads in the VerboseTF argument and interprets, using the above function.\n",
    "    \n",
    "    Inputs: \n",
    "        VerboseTF: Boolean input whereby True allows default command-line updates and False stops printing updates to the command line. \n",
    "    \"\"\"\n",
    "    with suppress_stdout():\n",
    "        PyESPER_Mixed(DesiredVariables, Path, OutputCoordinates, PredictorMeasurements, **kwargs) # Modify according to which PyESPER you're using"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
